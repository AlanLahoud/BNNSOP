{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.multiprocessing as mp\n",
    "import torch.nn as nn\n",
    "from qpth.qp import QPFunction\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import data_generator\n",
    "import params_newsvendor as params\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from model import VariationalLayer, VariationalNet, StandardNet, VariationalNet2\n",
    "\n",
    "from train import TrainDecoupled\n",
    "\n",
    "from train_normflow import TrainFlowDecoupled\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_cuda = False\n",
    "dev = torch.device('cpu')  \n",
    "if torch.cuda.is_available():\n",
    "    is_cuda = True\n",
    "    dev = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the seeds to allow replication\n",
    "# Changing the seed might require hyperparameter tuning again\n",
    "# Because it changes the deterministic parameters\n",
    "seed_number = 0\n",
    "np.random.seed(seed_number)\n",
    "torch.manual_seed(seed_number)\n",
    "random.seed(seed_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting parameters (change if necessary)\n",
    "N = 8000 # Total data size\n",
    "N_train = 5000 # Training data size\n",
    "N_SAMPLES = 16 # Sampling size while training\n",
    "BATCH_SIZE_LOADER = 32 # Standard batch size\n",
    "EPOCHS = 80 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nl = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "N_valid = N - N_train\n",
    "X, Y_original = data_generator.data_4to8(N_train, noise_level=nl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scaler_multi.gz']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output normalization\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(Y_original)\n",
    "tmean = torch.tensor(scaler.mean_)\n",
    "tstd = torch.tensor(scaler.scale_)\n",
    "joblib.dump(scaler, 'scaler_multi.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_transform(yy):\n",
    "    return yy*tstd + tmean\n",
    "\n",
    "Y = scaler.transform(Y_original).copy()\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "Y = torch.tensor(Y, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = data_generator.ArtificialDataset(X, Y)\n",
    "training_loader = torch.utils.data.DataLoader(\n",
    "    data_train, batch_size=BATCH_SIZE_LOADER,\n",
    "    shuffle=False, num_workers=mp.cpu_count())\n",
    "\n",
    "X_val, Y_val_original = data_generator.data_4to8(N_valid, noise_level=nl)\n",
    "Y_val = scaler.transform(Y_val_original).copy()\n",
    "X_val = torch.tensor(X_val, dtype=torch.float32)\n",
    "Y_val_original = torch.tensor(Y_val_original, dtype=torch.float32)\n",
    "Y_val = torch.tensor(Y_val, dtype=torch.float32)\n",
    "\n",
    "data_valid = data_generator.ArtificialDataset(X_val, Y_val)\n",
    "validation_loader = torch.utils.data.DataLoader(\n",
    "    data_valid, batch_size=BATCH_SIZE_LOADER,\n",
    "    shuffle=False, num_workers=mp.cpu_count())\n",
    "\n",
    "input_size = X.shape[1]\n",
    "output_size = Y.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SolveNewsvendorWithKKT():\n",
    "    def __init__(self, params_t, n_samples):\n",
    "        super(SolveNewsvendorWithKKT, self).__init__()\n",
    "            \n",
    "        n_items = len(params_t['c'])\n",
    "        self.n_items = n_items  \n",
    "        self.n_samples = n_samples\n",
    "            \n",
    "        # Torch parameters for KKT         \n",
    "        ident = torch.eye(n_items)\n",
    "        ident_samples = torch.eye(n_items*n_samples)\n",
    "        ident3 = torch.eye(n_items + 2*n_items*n_samples)\n",
    "        zeros_matrix = torch.zeros((n_items*n_samples, n_items*n_samples))\n",
    "        zeros_array = torch.zeros(n_items*n_samples)\n",
    "        ones_array = torch.ones(n_items*n_samples)\n",
    "             \n",
    "        self.Q = torch.diag(\n",
    "            torch.hstack(\n",
    "                (\n",
    "                    params_t['q'], \n",
    "                    (1/n_samples)*params_t['qs'].repeat_interleave(n_samples), \n",
    "                    (1/n_samples)*params_t['qw'].repeat_interleave(n_samples)\n",
    "                )\n",
    "            )).to(dev)\n",
    "        \n",
    "        \n",
    "        self.lin = torch.hstack(\n",
    "                                (\n",
    "                                    params_t['c'], \n",
    "                                    (1/n_samples)*params_t['cs'].repeat_interleave(n_samples), \n",
    "                                    (1/n_samples)*params_t['cw'].repeat_interleave(n_samples)\n",
    "                                )).to(dev)\n",
    "             \n",
    "            \n",
    "        shortage_ineq = torch.hstack(\n",
    "            (\n",
    "                -ident.repeat_interleave(n_samples, 0), \n",
    "                -ident_samples, \n",
    "                zeros_matrix\n",
    "            )\n",
    "        )  \n",
    "        \n",
    "        \n",
    "        excess_ineq = torch.hstack(\n",
    "            (\n",
    "                ident.repeat_interleave(n_samples, 0), \n",
    "                zeros_matrix, \n",
    "                -ident_samples\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        \n",
    "        price_ineq = torch.hstack(\n",
    "            (\n",
    "                params_t['pr'], \n",
    "                zeros_array, \n",
    "                zeros_array\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        \n",
    "        positive_ineq = -ident3\n",
    "        \n",
    "        \n",
    "        self.ineqs = torch.vstack(\n",
    "            (\n",
    "                shortage_ineq, \n",
    "                excess_ineq, \n",
    "                price_ineq, \n",
    "                positive_ineq\n",
    "            )\n",
    "        ).to(dev)\n",
    " \n",
    "        self.uncert_bound = torch.hstack((-ones_array, ones_array)).to(dev)\n",
    "        \n",
    "        self.determ_bound = torch.tensor([params_t['B']]) \n",
    "        \n",
    "        self.determ_bound = torch.hstack((self.determ_bound, \n",
    "                                          torch.zeros(n_items), \n",
    "                                          torch.zeros(n_items*n_samples), \n",
    "                                          torch.zeros(n_items*n_samples))).to(dev)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, y):\n",
    "        \"\"\"\n",
    "        Applies the qpth solver for all batches and allows backpropagation.\n",
    "        Formulation based on Priya L. Donti, Brandon Amos, J. Zico Kolter (2017).\n",
    "        Note: The quadratic terms (Q) are used as auxiliar terms only to allow the backpropagation through the \n",
    "        qpth library from Amos and Kolter. \n",
    "        We will set them as a small percentage of the linear terms (Wilder, Ewing, Dilkina, Tambe, 2019)\n",
    "        \"\"\"\n",
    "        \n",
    "        batch_size, n_samples_items = y.size()\n",
    "                \n",
    "        assert self.n_samples*self.n_items == n_samples_items \n",
    "\n",
    "        Q = self.Q\n",
    "        Q = Q.expand(batch_size, Q.size(0), Q.size(1))\n",
    "        \n",
    "        lin = self.lin\n",
    "        lin = lin.expand(batch_size, lin.size(0))\n",
    "\n",
    "        ineqs = torch.unsqueeze(self.ineqs, dim=0)\n",
    "        ineqs = ineqs.expand(batch_size, ineqs.shape[1], ineqs.shape[2])       \n",
    "\n",
    "        uncert_bound = (self.uncert_bound*torch.hstack((y, y)))\n",
    "        determ_bound = self.determ_bound.unsqueeze(dim=0).expand(\n",
    "            batch_size, self.determ_bound.shape[0])\n",
    "        bound = torch.hstack((uncert_bound, determ_bound))     \n",
    "        \n",
    "        e = torch.DoubleTensor().to(dev)\n",
    "        \n",
    "        argmin = QPFunction(verbose=-1)\\\n",
    "            (Q.double(), lin.double(), ineqs.double(), \n",
    "             bound.double(), e, e).double()\n",
    "            \n",
    "        return argmin[:,:n_items]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_per_item = lambda Z, Y : params_t['q'].to(dev)*Z.to(dev)**2 \\\n",
    "                            + params_t['qs'].to(dev)*(torch.max(torch.zeros((n_items)).to(dev),Y.to(dev)-Z.to(dev)))**2 \\\n",
    "                            + params_t['qw'].to(dev)*(torch.max(torch.zeros((n_items)).to(dev),Z.to(dev)-Y.to(dev)))**2 \\\n",
    "                            + params_t['c'].to(dev)*Z.to(dev) \\\n",
    "                            + params_t['cs'].to(dev)*torch.max(torch.zeros((n_items)).to(dev),Y.to(dev)-Z.to(dev)) \\\n",
    "                            + params_t['cw'].to(dev)*torch.max(torch.zeros((n_items)).to(dev),Z.to(dev)-Y.to(dev))\n",
    "\n",
    "\n",
    "def reshape_outcomes(y_pred):\n",
    "    n_samples = y_pred.shape[0]\n",
    "    batch_size = y_pred.shape[1]\n",
    "    n_items = y_pred.shape[2]\n",
    "\n",
    "    y_pred = y_pred.permute((1, 2, 0)).reshape((batch_size, n_samples*n_items))\n",
    "\n",
    "    return y_pred\n",
    "\n",
    "def calc_f_por_item(y_pred, y):\n",
    "    y_pred = reshape_outcomes(y_pred)\n",
    "    z_star =  argmin_solver(y_pred)\n",
    "    f_per_item = cost_per_item(z_star, y)\n",
    "    return f_per_item\n",
    "\n",
    "def calc_f_per_day(y_pred, y):\n",
    "    f_per_item = calc_f_por_item(y_pred, y)\n",
    "    f = torch.sum(f_per_item, 1)\n",
    "    return f\n",
    "\n",
    "def cost_fn(y_pred, y):\n",
    "    f = calc_f_per_day(y_pred, y)\n",
    "    f_total = torch.mean(f)\n",
    "    return f_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_ann = StandardNet(input_size, output_size, 0).to(dev)\n",
    "h_bnn = VariationalNet(N_SAMPLES, input_size, output_size, 1.0).to(dev)\n",
    "\n",
    "opt_h_ann = torch.optim.Adam(h_ann.parameters(), lr=0.0008)\n",
    "opt_h_bnn = torch.optim.Adam(h_bnn.parameters(), lr=0.0012)\n",
    "\n",
    "mse_loss = nn.MSELoss(reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------EPOCH 1------------------\n",
      "DATA LOSS \t train 0.532 valid 0.373\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.53 valid 0.37\n",
      "------------------EPOCH 2------------------\n",
      "DATA LOSS \t train 0.331 valid 0.315\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.33 valid 0.31\n",
      "------------------EPOCH 3------------------\n",
      "DATA LOSS \t train 0.288 valid 0.277\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.29 valid 0.28\n",
      "------------------EPOCH 4------------------\n",
      "DATA LOSS \t train 0.258 valid 0.254\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.26 valid 0.25\n",
      "------------------EPOCH 5------------------\n",
      "DATA LOSS \t train 0.239 valid 0.242\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.24 valid 0.24\n",
      "------------------EPOCH 6------------------\n",
      "DATA LOSS \t train 0.227 valid 0.236\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.23 valid 0.24\n",
      "------------------EPOCH 7------------------\n",
      "DATA LOSS \t train 0.218 valid 0.229\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.22 valid 0.23\n",
      "------------------EPOCH 8------------------\n",
      "DATA LOSS \t train 0.21 valid 0.224\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.21 valid 0.22\n",
      "------------------EPOCH 9------------------\n",
      "DATA LOSS \t train 0.203 valid 0.219\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.2 valid 0.22\n",
      "------------------EPOCH 10------------------\n",
      "DATA LOSS \t train 0.195 valid 0.215\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.2 valid 0.21\n",
      "------------------EPOCH 11------------------\n",
      "DATA LOSS \t train 0.187 valid 0.206\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.19 valid 0.21\n",
      "------------------EPOCH 12------------------\n",
      "DATA LOSS \t train 0.178 valid 0.197\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.18 valid 0.2\n",
      "------------------EPOCH 13------------------\n",
      "DATA LOSS \t train 0.169 valid 0.186\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.17 valid 0.19\n",
      "------------------EPOCH 14------------------\n",
      "DATA LOSS \t train 0.16 valid 0.176\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.16 valid 0.18\n",
      "------------------EPOCH 15------------------\n",
      "DATA LOSS \t train 0.151 valid 0.169\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.15 valid 0.17\n",
      "------------------EPOCH 16------------------\n",
      "DATA LOSS \t train 0.143 valid 0.161\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.14 valid 0.16\n",
      "------------------EPOCH 17------------------\n",
      "DATA LOSS \t train 0.137 valid 0.155\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.14 valid 0.16\n",
      "------------------EPOCH 18------------------\n",
      "DATA LOSS \t train 0.131 valid 0.151\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.13 valid 0.15\n",
      "------------------EPOCH 19------------------\n",
      "DATA LOSS \t train 0.126 valid 0.146\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.13 valid 0.15\n",
      "------------------EPOCH 20------------------\n",
      "DATA LOSS \t train 0.122 valid 0.143\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.12 valid 0.14\n",
      "------------------EPOCH 21------------------\n",
      "DATA LOSS \t train 0.118 valid 0.14\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.12 valid 0.14\n",
      "------------------EPOCH 22------------------\n",
      "DATA LOSS \t train 0.114 valid 0.135\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.11 valid 0.14\n",
      "------------------EPOCH 23------------------\n",
      "DATA LOSS \t train 0.11 valid 0.133\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.11 valid 0.13\n",
      "------------------EPOCH 24------------------\n",
      "DATA LOSS \t train 0.107 valid 0.13\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.11 valid 0.13\n",
      "------------------EPOCH 25------------------\n",
      "DATA LOSS \t train 0.104 valid 0.128\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.1 valid 0.13\n",
      "------------------EPOCH 26------------------\n",
      "DATA LOSS \t train 0.101 valid 0.125\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.1 valid 0.12\n",
      "------------------EPOCH 27------------------\n",
      "DATA LOSS \t train 0.098 valid 0.123\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.1 valid 0.12\n",
      "------------------EPOCH 28------------------\n",
      "DATA LOSS \t train 0.095 valid 0.121\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.1 valid 0.12\n",
      "------------------EPOCH 29------------------\n",
      "DATA LOSS \t train 0.093 valid 0.119\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.09 valid 0.12\n",
      "------------------EPOCH 30------------------\n",
      "DATA LOSS \t train 0.09 valid 0.116\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.09 valid 0.12\n",
      "------------------EPOCH 31------------------\n",
      "DATA LOSS \t train 0.088 valid 0.114\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.09 valid 0.11\n",
      "------------------EPOCH 32------------------\n",
      "DATA LOSS \t train 0.086 valid 0.111\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.09 valid 0.11\n",
      "------------------EPOCH 33------------------\n",
      "DATA LOSS \t train 0.084 valid 0.109\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.08 valid 0.11\n",
      "------------------EPOCH 34------------------\n",
      "DATA LOSS \t train 0.082 valid 0.107\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.08 valid 0.11\n",
      "------------------EPOCH 35------------------\n",
      "DATA LOSS \t train 0.08 valid 0.106\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.08 valid 0.11\n",
      "------------------EPOCH 36------------------\n",
      "DATA LOSS \t train 0.079 valid 0.104\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.08 valid 0.1\n",
      "------------------EPOCH 37------------------\n",
      "DATA LOSS \t train 0.077 valid 0.103\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.08 valid 0.1\n",
      "------------------EPOCH 38------------------\n",
      "DATA LOSS \t train 0.076 valid 0.101\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.08 valid 0.1\n",
      "------------------EPOCH 39------------------\n",
      "DATA LOSS \t train 0.075 valid 0.1\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.07 valid 0.1\n",
      "------------------EPOCH 40------------------\n",
      "DATA LOSS \t train 0.074 valid 0.099\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.07 valid 0.1\n",
      "------------------EPOCH 41------------------\n",
      "DATA LOSS \t train 0.073 valid 0.098\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.07 valid 0.1\n",
      "------------------EPOCH 42------------------\n",
      "DATA LOSS \t train 0.072 valid 0.097\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.07 valid 0.1\n",
      "------------------EPOCH 43------------------\n",
      "DATA LOSS \t train 0.071 valid 0.097\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.07 valid 0.1\n",
      "------------------EPOCH 44------------------\n",
      "DATA LOSS \t train 0.07 valid 0.096\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.07 valid 0.1\n",
      "------------------EPOCH 45------------------\n",
      "DATA LOSS \t train 0.07 valid 0.095\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.07 valid 0.1\n",
      "------------------EPOCH 46------------------\n"
     ]
    }
   ],
   "source": [
    "train_ANN = TrainDecoupled(\n",
    "                    bnn = False,\n",
    "                    model=h_ann,\n",
    "                    opt=opt_h_ann,\n",
    "                    loss_data=mse_loss,\n",
    "                    K=0.0,\n",
    "                    training_loader=training_loader,\n",
    "                    validation_loader=validation_loader\n",
    "                )\n",
    "\n",
    "train_ANN.train(EPOCHS=80)\n",
    "model_ann = train_ANN.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_BNN = TrainDecoupled(\n",
    "                    bnn = True,\n",
    "                    model=h_bnn,\n",
    "                    opt=opt_h_bnn,\n",
    "                    loss_data=mse_loss,\n",
    "                    K=1.0,\n",
    "                    training_loader=training_loader,\n",
    "                    validation_loader=validation_loader\n",
    "                )\n",
    "\n",
    "train_BNN.train(EPOCHS=120)\n",
    "model_bnn = train_BNN.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_flow = TrainFlowDecoupled(steps=2500, input_size=4, output_size=8)\n",
    "model_flow = train_flow.train(X, Y, X_val, Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_items = output_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_t, _ = params.get_params(n_items, seed_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Propagating predictions to Newsvendor Problem\n",
    "M = 16\n",
    "\n",
    "Y_pred_ANN = train_ANN.model(X_val).unsqueeze(0)\n",
    "Y_pred_ANN = inverse_transform(Y_pred_ANN)\n",
    "\n",
    "train_BNN.model.update_n_samples(n_samples=M)\n",
    "Y_pred_BNN = train_BNN.model.forward_dist(X_val)\n",
    "Y_pred_BNN = inverse_transform(Y_pred_BNN)\n",
    "#M = Y_pred_BNN.shape[0]\n",
    "\n",
    "N = X_val.shape[0]\n",
    "Y_pred_flow = torch.zeros((M, N, n_items))\n",
    "for i in range(0, N):\n",
    "    Y_pred_flow[:,i,:] = model_flow.condition(X_val[i]).sample(torch.Size([M,])).squeeze()\n",
    "Y_pred_flow = inverse_transform(Y_pred_flow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_loss = nn.MSELoss()\n",
    "print(mse_loss(Y_pred_ANN.mean(axis=0), Y_val_original))\n",
    "print(mse_loss(Y_pred_BNN.mean(axis=0), Y_val_original))\n",
    "print(mse_loss(Y_pred_flow.mean(axis=0), Y_val_original))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the solver\n",
    "newsvendor_solve_kkt = SolveNewsvendorWithKKT(params_t, 1)\n",
    "newsvendor_solve_kkt_M = SolveNewsvendorWithKKT(params_t, M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def argmin_solver(y_pred):\n",
    "    z_star = newsvendor_solve_kkt.forward(y_pred)\n",
    "    return z_star\n",
    "\n",
    "n_batches = int(np.ceil(Y_pred_ANN.shape[1]/BATCH_SIZE_LOADER))\n",
    "\n",
    "f_total = 0\n",
    "f_total_best = 0\n",
    "\n",
    "for b in range(0, n_batches):\n",
    "    i_low = b*BATCH_SIZE_LOADER\n",
    "    i_up = (b+1)*BATCH_SIZE_LOADER\n",
    "    if b == n_batches-1:\n",
    "        i_up = n_batches*Y_pred_ANN.shape[1]\n",
    "    f_total += cost_fn(Y_pred_ANN[:,i_low:i_up,:], Y_val_original[i_low:i_up,:])/n_batches\n",
    "    print(f_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def argmin_solver(y_pred):\n",
    "    z_star = newsvendor_solve_kkt_M.forward(y_pred)\n",
    "    return z_star\n",
    "\n",
    "n_batches = int(np.ceil(Y_pred_BNN.shape[1]/BATCH_SIZE_LOADER))\n",
    "\n",
    "f_total = 0\n",
    "f_total_best = 0\n",
    "\n",
    "for b in range(0, n_batches):\n",
    "    i_low = b*BATCH_SIZE_LOADER\n",
    "    i_up = (b+1)*BATCH_SIZE_LOADER\n",
    "    if b == n_batches-1:\n",
    "        i_up = n_batches*Y_pred_BNN.shape[1]\n",
    "    f_total += cost_fn(Y_pred_BNN[:,i_low:i_up,:], Y_val_original[i_low:i_up,:])/n_batches\n",
    "    print(f_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def argmin_solver(y_pred):\n",
    "    z_star = newsvendor_solve_kkt_M.forward(y_pred)\n",
    "    return z_star\n",
    "\n",
    "n_batches = int(np.ceil(Y_pred_flow.shape[1]/BATCH_SIZE_LOADER))\n",
    "\n",
    "f_total = 0\n",
    "f_total_best = 0\n",
    "\n",
    "for b in range(0, n_batches):\n",
    "    i_low = b*BATCH_SIZE_LOADER\n",
    "    i_up = (b+1)*BATCH_SIZE_LOADER\n",
    "    if b == n_batches-1:\n",
    "        i_up = n_batches*Y_pred_flow.shape[1]\n",
    "    f_total += cost_fn(Y_pred_flow[:,i_low:i_up,:], Y_val_original[i_low:i_up,:])/n_batches\n",
    "    print(f_total)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pao_env",
   "language": "python",
   "name": "pao_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
