{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.multiprocessing as mp\n",
    "import torch.nn as nn\n",
    "from qpth.qp import QPFunction\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import data_generator\n",
    "import params_newsvendor as params\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from model import VariationalNet, StandardNet, VariationalNet2\n",
    "\n",
    "from train import TrainDecoupled, TrainCombined\n",
    "\n",
    "from train_normflow import TrainFlowDecoupled, TrainFlowCombined\n",
    "\n",
    "import joblib\n",
    "\n",
    "\n",
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_count = mp.cpu_count()\n",
    "is_cuda = False\n",
    "dev = torch.device('cpu')  \n",
    "if torch.cuda.is_available():\n",
    "    is_cuda = True\n",
    "    dev = torch.device('cuda')\n",
    "    cpu_count = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the seeds to allow replication\n",
    "# Changing the seed might require hyperparameter tuning again\n",
    "# Because it changes the deterministic parameters\n",
    "seed_number = 0\n",
    "np.random.seed(seed_number)\n",
    "torch.manual_seed(seed_number)\n",
    "random.seed(seed_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting parameters (change if necessary)\n",
    "N = 8000 # Total data size\n",
    "N_train = 5000 # Training data size\n",
    "N_SAMPLES = 2 # Sampling size while training\n",
    "BATCH_SIZE_LOADER = 16 # Standard batch size\n",
    "EPOCHS = 150 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nl = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "N_valid = N - N_train\n",
    "X, Y_original = data_generator.data_4to8(N_train, noise_level=nl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scaler_multi.gz']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output normalization\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(Y_original)\n",
    "tmean = torch.tensor(scaler.mean_)\n",
    "tstd = torch.tensor(scaler.scale_)\n",
    "joblib.dump(scaler, 'scaler_multi.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_transform(yy):\n",
    "    return yy*tstd + tmean\n",
    "\n",
    "Y = scaler.transform(Y_original).copy()\n",
    "X = torch.tensor(X, dtype=torch.float32)#.to(dev)\n",
    "Y = torch.tensor(Y, dtype=torch.float32)#.to(dev)\n",
    "Y_original = torch.tensor(Y_original, dtype=torch.float32)#.to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_train_original = data_generator.ArtificialDataset(X, Y_original)\n",
    "training_loader_original = torch.utils.data.DataLoader(\n",
    "    data_train_original, batch_size=BATCH_SIZE_LOADER,\n",
    "    shuffle=False, num_workers=cpu_count)\n",
    "   \n",
    "    \n",
    "data_train = data_generator.ArtificialDataset(X, Y)\n",
    "training_loader = torch.utils.data.DataLoader(\n",
    "    data_train, batch_size=BATCH_SIZE_LOADER,\n",
    "    shuffle=False, num_workers=cpu_count)\n",
    "    \n",
    "    \n",
    "X_val, Y_val_original = data_generator.data_4to8(N_valid, noise_level=nl)\n",
    "Y_val = scaler.transform(Y_val_original).copy()\n",
    "X_val = torch.tensor(X_val, dtype=torch.float32)#.to(dev)\n",
    "Y_val_original = torch.tensor(Y_val_original, dtype=torch.float32)#.to(dev)\n",
    "Y_val = torch.tensor(Y_val, dtype=torch.float32)#.to(dev)\n",
    "\n",
    "\n",
    "data_valid_original = data_generator.ArtificialDataset(X_val, Y_val_original)\n",
    "validation_loader_original = torch.utils.data.DataLoader(\n",
    "    data_valid_original, batch_size=BATCH_SIZE_LOADER,\n",
    "    shuffle=False, num_workers=cpu_count)\n",
    "\n",
    "    \n",
    "data_valid = data_generator.ArtificialDataset(X_val, Y_val)\n",
    "validation_loader = torch.utils.data.DataLoader(\n",
    "    data_valid, batch_size=BATCH_SIZE_LOADER,\n",
    "    shuffle=False, num_workers=cpu_count)\n",
    "    \n",
    "input_size = X.shape[1]\n",
    "output_size = Y.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SolveNewsvendorWithKKT():\n",
    "    def __init__(self, params_t, n_samples):\n",
    "        super(SolveNewsvendorWithKKT, self).__init__()\n",
    "        \n",
    "        self.params_t = params_t\n",
    "        \n",
    "        n_items = len(params_t['c'])\n",
    "        self.n_items = n_items  \n",
    "        self.n_samples = n_samples\n",
    "        \n",
    "            \n",
    "        # Torch parameters for KKT         \n",
    "        ident = torch.eye(n_items).to(dev)\n",
    "        ident_samples = torch.eye(n_items*n_samples).to(dev)\n",
    "        ident3 = torch.eye(n_items + 2*n_items*n_samples).to(dev)\n",
    "        zeros_matrix = torch.zeros((n_items*n_samples, n_items*n_samples)).to(dev)\n",
    "        zeros_array = torch.zeros(n_items*n_samples).to(dev)\n",
    "        ones_array = torch.ones(n_items*n_samples).to(dev)\n",
    "             \n",
    "        self.Q = torch.diag(\n",
    "            torch.hstack(\n",
    "                (\n",
    "                    params_t['q'], \n",
    "                    (1/n_samples)*params_t['qs'].repeat_interleave(n_samples), \n",
    "                    (1/n_samples)*params_t['qw'].repeat_interleave(n_samples)\n",
    "                )\n",
    "            )).to(dev)\n",
    "        \n",
    "        \n",
    "        self.lin = torch.hstack(\n",
    "                                (\n",
    "                                    params_t['c'], \n",
    "                                    (1/n_samples)*params_t['cs'].repeat_interleave(n_samples), \n",
    "                                    (1/n_samples)*params_t['cw'].repeat_interleave(n_samples)\n",
    "                                )).to(dev)\n",
    "             \n",
    "            \n",
    "        shortage_ineq = torch.hstack(\n",
    "            (\n",
    "                -ident.repeat_interleave(n_samples, 0), \n",
    "                -ident_samples, \n",
    "                zeros_matrix\n",
    "            )\n",
    "        )  \n",
    "        \n",
    "        \n",
    "        excess_ineq = torch.hstack(\n",
    "            (\n",
    "                ident.repeat_interleave(n_samples, 0), \n",
    "                zeros_matrix, \n",
    "                -ident_samples\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        \n",
    "        price_ineq = torch.hstack(\n",
    "            (\n",
    "                params_t['pr'], \n",
    "                zeros_array, \n",
    "                zeros_array\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        \n",
    "        positive_ineq = -ident3\n",
    "        \n",
    "        \n",
    "        self.ineqs = torch.vstack(\n",
    "            (\n",
    "                shortage_ineq, \n",
    "                excess_ineq, \n",
    "                price_ineq, \n",
    "                positive_ineq\n",
    "            )\n",
    "        ).to(dev)\n",
    " \n",
    "        self.uncert_bound = torch.hstack((-ones_array, ones_array)).to(dev)\n",
    "        \n",
    "        self.determ_bound = torch.tensor([params_t['B']]) \n",
    "        \n",
    "        self.determ_bound = torch.hstack((self.determ_bound, \n",
    "                                          torch.zeros(n_items), \n",
    "                                          torch.zeros(n_items*n_samples), \n",
    "                                          torch.zeros(n_items*n_samples))).to(dev)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, y):\n",
    "        \"\"\"\n",
    "        Applies the qpth solver for all batches and allows backpropagation.\n",
    "        Formulation based on Priya L. Donti, Brandon Amos, J. Zico Kolter (2017).\n",
    "        Note: The quadratic terms (Q) are used as auxiliar terms only to allow the backpropagation through the \n",
    "        qpth library from Amos and Kolter. \n",
    "        We will set them as a small percentage of the linear terms (Wilder, Ewing, Dilkina, Tambe, 2019)\n",
    "        \"\"\"\n",
    "        \n",
    "        batch_size, n_samples_items = y.size()\n",
    "                \n",
    "        assert self.n_samples*self.n_items == n_samples_items \n",
    "\n",
    "        Q = self.Q\n",
    "        Q = Q.expand(batch_size, Q.size(0), Q.size(1))\n",
    "        \n",
    "        lin = self.lin\n",
    "        lin = lin.expand(batch_size, lin.size(0))\n",
    "\n",
    "        ineqs = torch.unsqueeze(self.ineqs, dim=0)\n",
    "        ineqs = ineqs.expand(batch_size, ineqs.shape[1], ineqs.shape[2])       \n",
    "\n",
    "        uncert_bound = (self.uncert_bound*torch.hstack((y, y)))\n",
    "        determ_bound = self.determ_bound.unsqueeze(dim=0).expand(\n",
    "            batch_size, self.determ_bound.shape[0])\n",
    "        bound = torch.hstack((uncert_bound, determ_bound))     \n",
    "        \n",
    "        e = torch.DoubleTensor().to(dev)\n",
    "        \n",
    "        argmin = QPFunction(verbose=-1)\\\n",
    "            (Q.double(), lin.double(), ineqs.double(), \n",
    "             bound.double(), e, e).double()\n",
    "            \n",
    "        return argmin[:,:n_items]\n",
    "    \n",
    "    def cost_per_item(self, Z, Y):\n",
    "        return params_t['q']*Z.to(dev)**2 \\\n",
    "            + self.params_t['qs']*(torch.max(torch.zeros((self.n_items)).to(dev),Y.to(dev)-Z.to(dev)))**2 \\\n",
    "            + self.params_t['qw']*(torch.max(torch.zeros((self.n_items)).to(dev),Z.to(dev)-Y.to(dev)))**2 \\\n",
    "            + self.params_t['c']*Z.to(dev) \\\n",
    "            + self.params_t['cs']*torch.max(torch.zeros((self.n_items)).to(dev),Y.to(dev)-Z.to(dev)) \\\n",
    "            + self.params_t['cw']*torch.max(torch.zeros((self.n_items)).to(dev),Z.to(dev)-Y.to(dev))\n",
    "\n",
    "    \n",
    "    def reshape_outcomes(self, y_pred):\n",
    "                \n",
    "        if len(y_pred.shape) == 2:\n",
    "            y_pred = y_pred.unsqueeze(0)\n",
    "\n",
    "        n_samples = y_pred.shape[0]\n",
    "        batch_size = y_pred.shape[1]\n",
    "        #n_items = y_pred.shape[2]\n",
    "        y_pred = y_pred.permute((1, 2, 0)).reshape((batch_size, n_samples*self.n_items))\n",
    "        return y_pred\n",
    "    \n",
    "    def calc_f_por_item(self, y_pred, y):\n",
    "        #pdb.set_trace()\n",
    "        y_pred = self.reshape_outcomes(y_pred)\n",
    "        z_star =  self.forward(y_pred)\n",
    "        f_per_item = self.cost_per_item(z_star, y)\n",
    "        return f_per_item\n",
    "\n",
    "    def calc_f_per_day(self, y_pred, y):\n",
    "        f_per_item = self.calc_f_por_item(y_pred, y)\n",
    "        f = torch.sum(f_per_item, 1)\n",
    "        return f\n",
    "\n",
    "    def end_loss(self, y_pred, y):\n",
    "        f = self.calc_f_per_day(y_pred, y)\n",
    "        f_total = torch.mean(f)\n",
    "        return f_total\n",
    "    \n",
    "    def end_loss_dist(self, y_pred, y):\n",
    "        f = self.calc_f_per_day(y_pred, y)\n",
    "        f_total = torch.mean(f)\n",
    "        return f_total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cost_per_item = lambda Z, Y : params_t['q'].to(dev)*Z.to(dev)**2 \\\n",
    "                            + params_t['qs'].to(dev)*(torch.max(torch.zeros((n_items)).to(dev),Y.to(dev)-Z.to(dev)))**2 \\\n",
    "                            + params_t['qw'].to(dev)*(torch.max(torch.zeros((n_items)).to(dev),Z.to(dev)-Y.to(dev)))**2 \\\n",
    "                            + params_t['c'].to(dev)*Z.to(dev) \\\n",
    "                            + params_t['cs'].to(dev)*torch.max(torch.zeros((n_items)).to(dev),Y.to(dev)-Z.to(dev)) \\\n",
    "                            + params_t['cw'].to(dev)*torch.max(torch.zeros((n_items)).to(dev),Z.to(dev)-Y.to(dev))\n",
    "\n",
    "\n",
    "def reshape_outcomes(y_pred):\n",
    "    n_samples = y_pred.shape[0]\n",
    "    batch_size = y_pred.shape[1]\n",
    "    n_items = y_pred.shape[2]\n",
    "\n",
    "    y_pred = y_pred.permute((1, 2, 0)).reshape((batch_size, n_samples*n_items))\n",
    "\n",
    "    return y_pred\n",
    "\n",
    "def calc_f_por_item(y_pred, y):\n",
    "    y_pred = reshape_outcomes(y_pred)\n",
    "    z_star =  argmin_solver(y_pred)\n",
    "    f_per_item = cost_per_item(z_star, y)\n",
    "    return f_per_item\n",
    "\n",
    "def calc_f_per_day(y_pred, y):\n",
    "    f_per_item = calc_f_por_item(y_pred, y)\n",
    "    f = torch.sum(f_per_item, 1)\n",
    "    return f\n",
    "\n",
    "def cost_fn(y_pred, y):\n",
    "    f = calc_f_per_day(y_pred, y)\n",
    "    f_total = torch.mean(f)\n",
    "    return f_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_ann_dec = StandardNet(input_size, output_size, 0).to(dev)\n",
    "h_bnn_dec = VariationalNet2(N_SAMPLES, input_size, output_size, 1.0, dev).to(dev)\n",
    "\n",
    "h_ann_com = StandardNet(input_size, output_size, 0).to(dev)\n",
    "h_bnn_com = VariationalNet2(N_SAMPLES, input_size, output_size, 1.0, dev).to(dev)\n",
    "\n",
    "opt_h_ann_dec = torch.optim.Adam(h_ann_dec.parameters(), lr=0.001)\n",
    "opt_h_bnn_dec = torch.optim.Adam(h_bnn_dec.parameters(), lr=0.001)\n",
    "\n",
    "opt_h_ann_com = torch.optim.Adam(h_ann_com.parameters(), lr=0.02)\n",
    "opt_h_bnn_com = torch.optim.Adam(h_bnn_com.parameters(), lr=0.02)\n",
    "\n",
    "mse_loss = nn.MSELoss(reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_items = output_size\n",
    "params_t, _ = params.get_params(n_items, seed_number, dev)\n",
    "\n",
    "# Construct the solver\n",
    "cn_constrained = SolveNewsvendorWithKKT(params_t, 1)\n",
    "cn_constrained_dist = SolveNewsvendorWithKKT(params_t, N_SAMPLES*4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------EPOCH 1------------------\n",
      "DATA LOSS \t train 0.453 valid 0.331\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.45 valid 0.33\n",
      "------------------EPOCH 2------------------\n",
      "DATA LOSS \t train 0.272 valid 0.269\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.27 valid 0.27\n",
      "------------------EPOCH 3------------------\n",
      "DATA LOSS \t train 0.23 valid 0.247\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.23 valid 0.25\n",
      "------------------EPOCH 4------------------\n",
      "DATA LOSS \t train 0.212 valid 0.235\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.21 valid 0.23\n",
      "------------------EPOCH 5------------------\n",
      "DATA LOSS \t train 0.199 valid 0.227\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.2 valid 0.23\n",
      "------------------EPOCH 6------------------\n",
      "DATA LOSS \t train 0.189 valid 0.221\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.19 valid 0.22\n",
      "------------------EPOCH 7------------------\n",
      "DATA LOSS \t train 0.179 valid 0.212\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.18 valid 0.21\n",
      "------------------EPOCH 8------------------\n",
      "DATA LOSS \t train 0.168 valid 0.197\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.17 valid 0.2\n",
      "------------------EPOCH 9------------------\n",
      "DATA LOSS \t train 0.154 valid 0.18\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.15 valid 0.18\n",
      "------------------EPOCH 10------------------\n",
      "DATA LOSS \t train 0.138 valid 0.167\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.14 valid 0.17\n",
      "------------------EPOCH 11------------------\n",
      "DATA LOSS \t train 0.126 valid 0.156\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.13 valid 0.16\n",
      "------------------EPOCH 12------------------\n",
      "DATA LOSS \t train 0.118 valid 0.148\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.12 valid 0.15\n",
      "------------------EPOCH 13------------------\n",
      "DATA LOSS \t train 0.111 valid 0.143\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.11 valid 0.14\n",
      "------------------EPOCH 14------------------\n",
      "DATA LOSS \t train 0.106 valid 0.138\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.11 valid 0.14\n",
      "------------------EPOCH 15------------------\n",
      "DATA LOSS \t train 0.101 valid 0.133\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.1 valid 0.13\n",
      "------------------EPOCH 16------------------\n",
      "DATA LOSS \t train 0.097 valid 0.129\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.1 valid 0.13\n",
      "------------------EPOCH 17------------------\n",
      "DATA LOSS \t train 0.093 valid 0.124\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.09 valid 0.12\n",
      "------------------EPOCH 18------------------\n",
      "DATA LOSS \t train 0.089 valid 0.12\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.09 valid 0.12\n",
      "------------------EPOCH 19------------------\n",
      "DATA LOSS \t train 0.086 valid 0.116\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.09 valid 0.12\n",
      "------------------EPOCH 20------------------\n",
      "DATA LOSS \t train 0.083 valid 0.112\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.08 valid 0.11\n",
      "------------------EPOCH 21------------------\n",
      "DATA LOSS \t train 0.08 valid 0.109\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.08 valid 0.11\n",
      "------------------EPOCH 22------------------\n",
      "DATA LOSS \t train 0.078 valid 0.107\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.08 valid 0.11\n",
      "------------------EPOCH 23------------------\n",
      "DATA LOSS \t train 0.076 valid 0.104\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.08 valid 0.1\n",
      "------------------EPOCH 24------------------\n",
      "DATA LOSS \t train 0.074 valid 0.102\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.07 valid 0.1\n",
      "------------------EPOCH 25------------------\n",
      "DATA LOSS \t train 0.072 valid 0.101\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.07 valid 0.1\n",
      "------------------EPOCH 26------------------\n",
      "DATA LOSS \t train 0.071 valid 0.099\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.07 valid 0.1\n",
      "------------------EPOCH 27------------------\n",
      "DATA LOSS \t train 0.07 valid 0.098\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.07 valid 0.1\n",
      "------------------EPOCH 28------------------\n",
      "DATA LOSS \t train 0.069 valid 0.098\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.07 valid 0.1\n",
      "------------------EPOCH 29------------------\n",
      "DATA LOSS \t train 0.068 valid 0.096\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.07 valid 0.1\n",
      "------------------EPOCH 30------------------\n",
      "DATA LOSS \t train 0.067 valid 0.095\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.07 valid 0.1\n",
      "------------------EPOCH 31------------------\n",
      "DATA LOSS \t train 0.066 valid 0.094\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.07 valid 0.09\n",
      "------------------EPOCH 32------------------\n",
      "DATA LOSS \t train 0.065 valid 0.092\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.06 valid 0.09\n",
      "------------------EPOCH 33------------------\n",
      "DATA LOSS \t train 0.064 valid 0.094\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.06 valid 0.09\n",
      "------------------EPOCH 34------------------\n",
      "DATA LOSS \t train 0.063 valid 0.092\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.06 valid 0.09\n",
      "------------------EPOCH 35------------------\n",
      "DATA LOSS \t train 0.063 valid 0.092\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.06 valid 0.09\n",
      "------------------EPOCH 36------------------\n",
      "DATA LOSS \t train 0.062 valid 0.092\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.06 valid 0.09\n",
      "------------------EPOCH 37------------------\n",
      "DATA LOSS \t train 0.062 valid 0.09\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.06 valid 0.09\n",
      "------------------EPOCH 38------------------\n",
      "DATA LOSS \t train 0.061 valid 0.091\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.06 valid 0.09\n",
      "------------------EPOCH 39------------------\n",
      "DATA LOSS \t train 0.061 valid 0.091\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.06 valid 0.09\n",
      "------------------EPOCH 40------------------\n",
      "DATA LOSS \t train 0.06 valid 0.09\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.06 valid 0.09\n",
      "------------------EPOCH 41------------------\n",
      "DATA LOSS \t train 0.06 valid 0.091\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.06 valid 0.09\n",
      "------------------EPOCH 42------------------\n",
      "DATA LOSS \t train 0.059 valid 0.09\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.06 valid 0.09\n",
      "------------------EPOCH 43------------------\n",
      "DATA LOSS \t train 0.059 valid 0.09\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.06 valid 0.09\n",
      "------------------EPOCH 44------------------\n",
      "DATA LOSS \t train 0.058 valid 0.09\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.06 valid 0.09\n",
      "------------------EPOCH 45------------------\n",
      "DATA LOSS \t train 0.058 valid 0.089\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.06 valid 0.09\n",
      "------------------EPOCH 46------------------\n",
      "DATA LOSS \t train 0.057 valid 0.088\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.06 valid 0.09\n",
      "------------------EPOCH 47------------------\n",
      "DATA LOSS \t train 0.057 valid 0.088\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.06 valid 0.09\n",
      "------------------EPOCH 48------------------\n",
      "DATA LOSS \t train 0.057 valid 0.089\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.06 valid 0.09\n",
      "------------------EPOCH 49------------------\n",
      "DATA LOSS \t train 0.056 valid 0.088\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.06 valid 0.09\n",
      "------------------EPOCH 50------------------\n",
      "DATA LOSS \t train 0.056 valid 0.089\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.06 valid 0.09\n",
      "------------------EPOCH 51------------------\n",
      "DATA LOSS \t train 0.056 valid 0.088\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.06 valid 0.09\n",
      "------------------EPOCH 52------------------\n",
      "DATA LOSS \t train 0.055 valid 0.089\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.06 valid 0.09\n",
      "------------------EPOCH 53------------------\n",
      "DATA LOSS \t train 0.055 valid 0.088\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.05 valid 0.09\n",
      "------------------EPOCH 54------------------\n",
      "DATA LOSS \t train 0.055 valid 0.088\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.06 valid 0.09\n",
      "------------------EPOCH 55------------------\n",
      "DATA LOSS \t train 0.055 valid 0.089\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.05 valid 0.09\n",
      "------------------EPOCH 56------------------\n",
      "DATA LOSS \t train 0.055 valid 0.089\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.05 valid 0.09\n",
      "------------------EPOCH 57------------------\n",
      "DATA LOSS \t train 0.054 valid 0.087\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.05 valid 0.09\n",
      "------------------EPOCH 58------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA LOSS \t train 0.054 valid 0.09\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.05 valid 0.09\n",
      "------------------EPOCH 59------------------\n",
      "DATA LOSS \t train 0.053 valid 0.089\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.05 valid 0.09\n",
      "------------------EPOCH 60------------------\n",
      "DATA LOSS \t train 0.053 valid 0.089\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.05 valid 0.09\n",
      "------------------EPOCH 61------------------\n",
      "DATA LOSS \t train 0.053 valid 0.09\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.05 valid 0.09\n",
      "------------------EPOCH 62------------------\n",
      "DATA LOSS \t train 0.053 valid 0.089\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.05 valid 0.09\n",
      "------------------EPOCH 63------------------\n",
      "DATA LOSS \t train 0.053 valid 0.088\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.05 valid 0.09\n",
      "------------------EPOCH 64------------------\n",
      "DATA LOSS \t train 0.052 valid 0.089\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.05 valid 0.09\n",
      "------------------EPOCH 65------------------\n",
      "DATA LOSS \t train 0.052 valid 0.091\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.05 valid 0.09\n",
      "------------------EPOCH 66------------------\n",
      "DATA LOSS \t train 0.052 valid 0.089\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.05 valid 0.09\n",
      "------------------EPOCH 67------------------\n",
      "DATA LOSS \t train 0.052 valid 0.088\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.05 valid 0.09\n",
      "------------------EPOCH 68------------------\n",
      "DATA LOSS \t train 0.051 valid 0.089\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.05 valid 0.09\n",
      "------------------EPOCH 69------------------\n",
      "DATA LOSS \t train 0.051 valid 0.089\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.05 valid 0.09\n",
      "------------------EPOCH 70------------------\n",
      "DATA LOSS \t train 0.051 valid 0.089\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.05 valid 0.09\n",
      "------------------EPOCH 71------------------\n",
      "DATA LOSS \t train 0.051 valid 0.092\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.05 valid 0.09\n",
      "------------------EPOCH 72------------------\n",
      "DATA LOSS \t train 0.051 valid 0.089\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.05 valid 0.09\n",
      "------------------EPOCH 73------------------\n",
      "DATA LOSS \t train 0.051 valid 0.09\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.05 valid 0.09\n",
      "------------------EPOCH 74------------------\n",
      "DATA LOSS \t train 0.051 valid 0.089\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.05 valid 0.09\n",
      "------------------EPOCH 75------------------\n",
      "DATA LOSS \t train 0.05 valid 0.092\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.05 valid 0.09\n",
      "------------------EPOCH 76------------------\n",
      "DATA LOSS \t train 0.05 valid 0.089\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.05 valid 0.09\n",
      "------------------EPOCH 77------------------\n",
      "DATA LOSS \t train 0.049 valid 0.09\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.05 valid 0.09\n",
      "------------------EPOCH 78------------------\n",
      "DATA LOSS \t train 0.049 valid 0.089\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.05 valid 0.09\n",
      "------------------EPOCH 79------------------\n",
      "DATA LOSS \t train 0.049 valid 0.089\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.05 valid 0.09\n",
      "------------------EPOCH 80------------------\n",
      "DATA LOSS \t train 0.049 valid 0.092\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.05 valid 0.09\n",
      "------------------EPOCH 81------------------\n",
      "DATA LOSS \t train 0.049 valid 0.09\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.05 valid 0.09\n",
      "------------------EPOCH 82------------------\n",
      "DATA LOSS \t train 0.049 valid 0.09\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.05 valid 0.09\n",
      "------------------EPOCH 83------------------\n",
      "DATA LOSS \t train 0.049 valid 0.092\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.05 valid 0.09\n",
      "------------------EPOCH 84------------------\n",
      "DATA LOSS \t train 0.049 valid 0.093\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.05 valid 0.09\n",
      "------------------EPOCH 85------------------\n",
      "DATA LOSS \t train 0.048 valid 0.091\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.05 valid 0.09\n",
      "------------------EPOCH 86------------------\n",
      "DATA LOSS \t train 0.048 valid 0.091\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.05 valid 0.09\n",
      "------------------EPOCH 87------------------\n",
      "DATA LOSS \t train 0.048 valid 0.092\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.05 valid 0.09\n",
      "------------------EPOCH 88------------------\n",
      "DATA LOSS \t train 0.048 valid 0.091\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.05 valid 0.09\n",
      "------------------EPOCH 89------------------\n",
      "DATA LOSS \t train 0.047 valid 0.093\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.05 valid 0.09\n",
      "------------------EPOCH 90------------------\n",
      "DATA LOSS \t train 0.047 valid 0.091\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.05 valid 0.09\n",
      "------------------EPOCH 91------------------\n",
      "DATA LOSS \t train 0.048 valid 0.094\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.05 valid 0.09\n",
      "------------------EPOCH 92------------------\n",
      "DATA LOSS \t train 0.047 valid 0.091\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.05 valid 0.09\n",
      "------------------EPOCH 93------------------\n",
      "DATA LOSS \t train 0.047 valid 0.092\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.05 valid 0.09\n",
      "------------------EPOCH 94------------------\n",
      "DATA LOSS \t train 0.047 valid 0.094\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.05 valid 0.09\n",
      "------------------EPOCH 95------------------\n",
      "DATA LOSS \t train 0.047 valid 0.092\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.05 valid 0.09\n",
      "------------------EPOCH 96------------------\n",
      "DATA LOSS \t train 0.047 valid 0.093\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.05 valid 0.09\n",
      "------------------EPOCH 97------------------\n",
      "DATA LOSS \t train 0.047 valid 0.092\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.05 valid 0.09\n",
      "------------------EPOCH 98------------------\n",
      "DATA LOSS \t train 0.047 valid 0.097\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.05 valid 0.1\n",
      "------------------EPOCH 99------------------\n",
      "DATA LOSS \t train 0.046 valid 0.093\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.05 valid 0.09\n",
      "------------------EPOCH 100------------------\n",
      "DATA LOSS \t train 0.046 valid 0.095\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.05 valid 0.09\n",
      "------------------EPOCH 101------------------\n",
      "DATA LOSS \t train 0.046 valid 0.096\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.05 valid 0.1\n",
      "------------------EPOCH 102------------------\n",
      "DATA LOSS \t train 0.046 valid 0.096\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.05 valid 0.1\n",
      "------------------EPOCH 103------------------\n",
      "DATA LOSS \t train 0.046 valid 0.095\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.05 valid 0.1\n",
      "------------------EPOCH 104------------------\n",
      "DATA LOSS \t train 0.046 valid 0.097\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.05 valid 0.1\n",
      "------------------EPOCH 105------------------\n",
      "DATA LOSS \t train 0.047 valid 0.096\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.05 valid 0.1\n",
      "------------------EPOCH 106------------------\n",
      "DATA LOSS \t train 0.047 valid 0.1\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.05 valid 0.1\n",
      "------------------EPOCH 107------------------\n",
      "DATA LOSS \t train 0.047 valid 0.094\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.05 valid 0.09\n",
      "------------------EPOCH 108------------------\n",
      "DATA LOSS \t train 0.046 valid 0.094\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.05 valid 0.09\n",
      "------------------EPOCH 109------------------\n",
      "DATA LOSS \t train 0.045 valid 0.094\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.05 valid 0.09\n",
      "------------------EPOCH 110------------------\n",
      "DATA LOSS \t train 0.045 valid 0.096\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.04 valid 0.1\n",
      "------------------EPOCH 111------------------\n",
      "DATA LOSS \t train 0.046 valid 0.099\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.05 valid 0.1\n",
      "------------------EPOCH 112------------------\n",
      "DATA LOSS \t train 0.045 valid 0.093\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.05 valid 0.09\n",
      "------------------EPOCH 113------------------\n",
      "DATA LOSS \t train 0.044 valid 0.092\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.04 valid 0.09\n",
      "------------------EPOCH 114------------------\n",
      "DATA LOSS \t train 0.044 valid 0.094\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.04 valid 0.09\n",
      "------------------EPOCH 115------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA LOSS \t train 0.044 valid 0.094\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.04 valid 0.09\n",
      "------------------EPOCH 116------------------\n",
      "DATA LOSS \t train 0.045 valid 0.095\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.04 valid 0.09\n",
      "------------------EPOCH 117------------------\n",
      "DATA LOSS \t train 0.044 valid 0.093\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.04 valid 0.09\n",
      "------------------EPOCH 118------------------\n",
      "DATA LOSS \t train 0.044 valid 0.094\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.04 valid 0.09\n",
      "------------------EPOCH 119------------------\n",
      "DATA LOSS \t train 0.044 valid 0.094\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.04 valid 0.09\n",
      "------------------EPOCH 120------------------\n",
      "DATA LOSS \t train 0.044 valid 0.095\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.04 valid 0.09\n",
      "------------------EPOCH 121------------------\n",
      "DATA LOSS \t train 0.044 valid 0.094\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.04 valid 0.09\n",
      "------------------EPOCH 122------------------\n",
      "DATA LOSS \t train 0.043 valid 0.094\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.04 valid 0.09\n",
      "------------------EPOCH 123------------------\n",
      "DATA LOSS \t train 0.043 valid 0.094\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.04 valid 0.09\n",
      "------------------EPOCH 124------------------\n",
      "DATA LOSS \t train 0.044 valid 0.097\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.04 valid 0.1\n",
      "------------------EPOCH 125------------------\n",
      "DATA LOSS \t train 0.044 valid 0.097\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.04 valid 0.1\n",
      "------------------EPOCH 126------------------\n",
      "DATA LOSS \t train 0.044 valid 0.096\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.04 valid 0.1\n",
      "------------------EPOCH 127------------------\n",
      "DATA LOSS \t train 0.044 valid 0.093\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.04 valid 0.09\n",
      "------------------EPOCH 128------------------\n",
      "DATA LOSS \t train 0.044 valid 0.093\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.04 valid 0.09\n",
      "------------------EPOCH 129------------------\n",
      "DATA LOSS \t train 0.044 valid 0.093\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.04 valid 0.09\n",
      "------------------EPOCH 130------------------\n",
      "DATA LOSS \t train 0.043 valid 0.095\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.04 valid 0.1\n",
      "------------------EPOCH 131------------------\n",
      "DATA LOSS \t train 0.042 valid 0.094\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.04 valid 0.09\n",
      "------------------EPOCH 132------------------\n",
      "DATA LOSS \t train 0.043 valid 0.094\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.04 valid 0.09\n",
      "------------------EPOCH 133------------------\n",
      "DATA LOSS \t train 0.044 valid 0.094\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.04 valid 0.09\n",
      "------------------EPOCH 134------------------\n",
      "DATA LOSS \t train 0.043 valid 0.096\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.04 valid 0.1\n",
      "------------------EPOCH 135------------------\n",
      "DATA LOSS \t train 0.043 valid 0.094\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.04 valid 0.09\n",
      "------------------EPOCH 136------------------\n",
      "DATA LOSS \t train 0.044 valid 0.094\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.04 valid 0.09\n",
      "------------------EPOCH 137------------------\n",
      "DATA LOSS \t train 0.042 valid 0.092\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.04 valid 0.09\n",
      "------------------EPOCH 138------------------\n",
      "DATA LOSS \t train 0.042 valid 0.095\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.04 valid 0.09\n",
      "------------------EPOCH 139------------------\n",
      "DATA LOSS \t train 0.044 valid 0.095\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.04 valid 0.1\n",
      "------------------EPOCH 140------------------\n",
      "DATA LOSS \t train 0.042 valid 0.096\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.04 valid 0.1\n",
      "------------------EPOCH 141------------------\n",
      "DATA LOSS \t train 0.042 valid 0.093\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.04 valid 0.09\n",
      "------------------EPOCH 142------------------\n",
      "DATA LOSS \t train 0.041 valid 0.095\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.04 valid 0.1\n",
      "------------------EPOCH 143------------------\n",
      "DATA LOSS \t train 0.041 valid 0.093\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.04 valid 0.09\n",
      "------------------EPOCH 144------------------\n",
      "DATA LOSS \t train 0.042 valid 0.095\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.04 valid 0.09\n",
      "------------------EPOCH 145------------------\n",
      "DATA LOSS \t train 0.042 valid 0.093\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.04 valid 0.09\n",
      "------------------EPOCH 146------------------\n",
      "DATA LOSS \t train 0.041 valid 0.094\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.04 valid 0.09\n",
      "------------------EPOCH 147------------------\n",
      "DATA LOSS \t train 0.042 valid 0.096\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.04 valid 0.1\n",
      "------------------EPOCH 148------------------\n",
      "DATA LOSS \t train 0.041 valid 0.093\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.04 valid 0.09\n",
      "------------------EPOCH 149------------------\n",
      "DATA LOSS \t train 0.041 valid 0.094\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.04 valid 0.09\n",
      "------------------EPOCH 150------------------\n",
      "DATA LOSS \t train 0.042 valid 0.094\n",
      "KL LOSS \t train 0.0 valid 0.0\n",
      "ELBO LOSS \t train 0.04 valid 0.09\n"
     ]
    }
   ],
   "source": [
    "train_ANN_dec = TrainDecoupled(\n",
    "                    bnn = False,\n",
    "                    model=h_ann_dec,\n",
    "                    opt=opt_h_ann_dec,\n",
    "                    loss_data=mse_loss,\n",
    "                    K=0.0,\n",
    "                    training_loader=training_loader,\n",
    "                    validation_loader=validation_loader,\n",
    "                    dev = dev\n",
    "                )\n",
    "\n",
    "train_ANN_dec.train(EPOCHS=EPOCHS)\n",
    "model_ann_dec = train_ANN_dec.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------EPOCH 1------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/qpth/qp.py:83: UserWarning: torch.eig is deprecated in favor of torch.linalg.eig and will be removed in a future PyTorch release.\n",
      "torch.linalg.eig returns complex tensors of dtype cfloat or cdouble rather than real tensors mimicking complex tensors.\n",
      "L, _ = torch.eig(A)\n",
      "should be replaced with\n",
      "L_complex = torch.linalg.eigvals(A)\n",
      "and\n",
      "L, V = torch.eig(A, eigenvectors=True)\n",
      "should be replaced with\n",
      "L_complex, V_complex = torch.linalg.eig(A) (Triggered internally at  /pytorch/aten/src/ATen/native/BatchLinearAlgebra.cpp:2897.)\n",
      "  e, _ = torch.eig(Q[i])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END LOSS \t train 39427.486 valid 37610.407\n",
      "------------------EPOCH 2------------------\n",
      "END LOSS \t train 37102.993 valid 33098.451\n",
      "------------------EPOCH 3------------------\n",
      "END LOSS \t train 32870.802 valid 32732.085\n",
      "------------------EPOCH 4------------------\n",
      "END LOSS \t train 32260.885 valid 31497.839\n",
      "------------------EPOCH 5------------------\n",
      "END LOSS \t train 30763.131 valid 30515.337\n",
      "------------------EPOCH 6------------------\n",
      "END LOSS \t train 29971.768 valid 29951.258\n",
      "------------------EPOCH 7------------------\n",
      "END LOSS \t train 29779.219 valid 30236.306\n",
      "------------------EPOCH 8------------------\n",
      "END LOSS \t train 29594.808 valid 29352.657\n",
      "------------------EPOCH 9------------------\n",
      "END LOSS \t train 29485.061 valid 29247.995\n",
      "------------------EPOCH 10------------------\n",
      "END LOSS \t train 29299.809 valid 29345.661\n",
      "------------------EPOCH 11------------------\n",
      "END LOSS \t train 29199.379 valid 29182.196\n",
      "------------------EPOCH 12------------------\n",
      "END LOSS \t train 29212.218 valid 29287.508\n",
      "------------------EPOCH 13------------------\n",
      "END LOSS \t train 29072.265 valid 29126.877\n",
      "------------------EPOCH 14------------------\n",
      "END LOSS \t train 29046.864 valid 29080.052\n",
      "------------------EPOCH 15------------------\n",
      "END LOSS \t train 28996.404 valid 29060.788\n",
      "------------------EPOCH 16------------------\n",
      "END LOSS \t train 28953.236 valid 28889.923\n",
      "------------------EPOCH 17------------------\n",
      "END LOSS \t train 28873.011 valid 28837.954\n",
      "------------------EPOCH 18------------------\n",
      "END LOSS \t train 28881.947 valid 28776.907\n",
      "------------------EPOCH 19------------------\n",
      "END LOSS \t train 28855.329 valid 28620.033\n",
      "------------------EPOCH 20------------------\n",
      "END LOSS \t train 28825.375 valid 28577.357\n",
      "------------------EPOCH 21------------------\n",
      "END LOSS \t train 28693.741 valid 28664.155\n",
      "------------------EPOCH 22------------------\n",
      "END LOSS \t train 28723.12 valid 28667.752\n",
      "------------------EPOCH 23------------------\n",
      "END LOSS \t train 28696.197 valid 28612.579\n",
      "------------------EPOCH 24------------------\n",
      "END LOSS \t train 28716.672 valid 28660.303\n",
      "------------------EPOCH 25------------------\n",
      "END LOSS \t train 28714.268 valid 28619.051\n",
      "------------------EPOCH 26------------------\n",
      "END LOSS \t train 28703.079 valid 28744.402\n",
      "------------------EPOCH 27------------------\n",
      "END LOSS \t train 28655.652 valid 28598.966\n",
      "------------------EPOCH 28------------------\n",
      "END LOSS \t train 28597.659 valid 28580.491\n",
      "------------------EPOCH 29------------------\n",
      "END LOSS \t train 28622.192 valid 28668.892\n",
      "------------------EPOCH 30------------------\n",
      "END LOSS \t train 28620.027 valid 28579.56\n",
      "------------------EPOCH 31------------------\n",
      "END LOSS \t train 28574.069 valid 28505.499\n",
      "------------------EPOCH 32------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-13-cbc877b21992>\", line 11, in <module>\n",
      "    train_ANN_com.train(EPOCHS=35)\n",
      "  File \"/repository/code/pao_uncertainty/train.py\", line 192, in train\n",
      "    avg_loss = self.train_one_epoch()\n",
      "  File \"/repository/code/pao_uncertainty/train.py\", line 170, in train_one_epoch\n",
      "    total_loss = self.end_loss(y_preds, y_batch)\n",
      "  File \"<ipython-input-10-2ca3ce4ac7b4>\", line 156, in end_loss\n",
      "    f = self.calc_f_per_day(y_pred, y)\n",
      "  File \"<ipython-input-10-2ca3ce4ac7b4>\", line 151, in calc_f_per_day\n",
      "    f_per_item = self.calc_f_por_item(y_pred, y)\n",
      "  File \"<ipython-input-10-2ca3ce4ac7b4>\", line 146, in calc_f_por_item\n",
      "    z_star =  self.forward(y_pred)\n",
      "  File \"<ipython-input-10-2ca3ce4ac7b4>\", line 119, in forward\n",
      "    bound.double(), e, e).double()\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/qpth/qp.py\", line 96, in forward\n",
      "    eps, verbose, notImprovedLim, maxIter)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/qpth/solvers/pdipm/batch.py\", line 132, in forward\n",
      "    best['resids'][I] = resids[I]\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 1169, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 1490, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 1448, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 739, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 709, in getabsfile\n",
      "    return os.path.normcase(os.path.abspath(_filename))\n",
      "  File \"/usr/lib/python3.6/posixpath.py\", line 385, in abspath\n",
      "    return normpath(path)\n",
      "  File \"/usr/lib/python3.6/posixpath.py\", line 366, in normpath\n",
      "    new_comps.append(comp)\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-13-cbc877b21992>\", line 11, in <module>\n",
      "    train_ANN_com.train(EPOCHS=35)\n",
      "  File \"/repository/code/pao_uncertainty/train.py\", line 192, in train\n",
      "    avg_loss = self.train_one_epoch()\n",
      "  File \"/repository/code/pao_uncertainty/train.py\", line 170, in train_one_epoch\n",
      "    total_loss = self.end_loss(y_preds, y_batch)\n",
      "  File \"<ipython-input-10-2ca3ce4ac7b4>\", line 156, in end_loss\n",
      "    f = self.calc_f_per_day(y_pred, y)\n",
      "  File \"<ipython-input-10-2ca3ce4ac7b4>\", line 151, in calc_f_per_day\n",
      "    f_per_item = self.calc_f_por_item(y_pred, y)\n",
      "  File \"<ipython-input-10-2ca3ce4ac7b4>\", line 146, in calc_f_por_item\n",
      "    z_star =  self.forward(y_pred)\n",
      "  File \"<ipython-input-10-2ca3ce4ac7b4>\", line 119, in forward\n",
      "    bound.double(), e, e).double()\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/qpth/qp.py\", line 96, in forward\n",
      "    eps, verbose, notImprovedLim, maxIter)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/qpth/solvers/pdipm/batch.py\", line 132, in forward\n",
      "    best['resids'][I] = resids[I]\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 3263, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 3360, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2047, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 1436, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 1336, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 1193, in structured_traceback\n",
      "    tb_offset)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 1150, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 451, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 1169, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 1490, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 1448, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 71, in ismodule\n",
      "    return isinstance(object, types.ModuleType)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-cbc877b21992>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mtrain_ANN_com\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m35\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mmodel_ann_com\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_ANN_com\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/repository/code/pao_uncertainty/train.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, EPOCHS)\u001b[0m\n\u001b[1;32m    191\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m             \u001b[0mavg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/repository/code/pao_uncertainty/train.py\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    169\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m                 \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-2ca3ce4ac7b4>\u001b[0m in \u001b[0;36mend_loss\u001b[0;34m(self, y_pred, y)\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mend_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalc_f_per_day\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m         \u001b[0mf_total\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-2ca3ce4ac7b4>\u001b[0m in \u001b[0;36mcalc_f_per_day\u001b[0;34m(self, y_pred, y)\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcalc_f_per_day\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m         \u001b[0mf_per_item\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalc_f_por_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_per_item\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-2ca3ce4ac7b4>\u001b[0m in \u001b[0;36mcalc_f_por_item\u001b[0;34m(self, y_pred, y)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape_outcomes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0mz_star\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m         \u001b[0mf_per_item\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcost_per_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_star\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-2ca3ce4ac7b4>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    118\u001b[0m             (Q.double(), lin.double(), ineqs.double(), \n\u001b[0;32m--> 119\u001b[0;31m              bound.double(), e, e).double()\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/qpth/qp.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, Q_, p_, G_, h_, A_, b_)\u001b[0m\n\u001b[1;32m     95\u001b[0m                     \u001b[0mQ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQ_LU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mS_LU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m                     eps, verbose, notImprovedLim, maxIter)\n\u001b[0m\u001b[1;32m     97\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0msolver\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mQPSolvers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCVXPY\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/qpth/solvers/pdipm/batch.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(Q, p, G, h, A, b, Q_LU, S_LU, R, eps, verbose, notImprovedLim, maxIter, solver)\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0mI_nineq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mI\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnineq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m             \u001b[0mbest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'resids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mI\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mI\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m             \u001b[0mbest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mI_nz\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mI_nz\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2043\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2044\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2045\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_ast_nodes\u001b[0;34m(self, nodelist, cell_name, interactivity, compiler, result)\u001b[0m\n\u001b[1;32m   3262\u001b[0m                         \u001b[0masy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3263\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0masync_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0masy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3264\u001b[0m                         \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2046\u001b[0m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0;32m-> 2047\u001b[0;31m                                             value, tb, tb_offset=tb_offset)\n\u001b[0m\u001b[1;32m   2048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1435\u001b[0m         return FormattedTB.structured_traceback(\n\u001b[0;32m-> 1436\u001b[0;31m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0m\u001b[1;32m   1437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1335\u001b[0m             return VerboseTB.structured_traceback(\n\u001b[0;32m-> 1336\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m             )\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0;32m-> 1193\u001b[0;31m                                                                tb_offset)\n\u001b[0m\u001b[1;32m   1194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1150\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2043\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2044\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2045\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'TypeError' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/async_helpers.py\u001b[0m in \u001b[0;36m_pseudo_sync_runner\u001b[0;34m(coro)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \"\"\"\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0mcoro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_async\u001b[0;34m(self, raw_cell, store_history, silent, shell_futures)\u001b[0m\n\u001b[1;32m   3070\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3071\u001b[0m                 has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n\u001b[0;32m-> 3072\u001b[0;31m                        interactivity=interactivity, compiler=compiler, result=result)\n\u001b[0m\u001b[1;32m   3073\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3074\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_execution_succeeded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_raised\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_ast_nodes\u001b[0;34m(self, nodelist, cell_name, interactivity, compiler, result)\u001b[0m\n\u001b[1;32m   3280\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3281\u001b[0m                 \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_before_exec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3282\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3283\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2045\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2046\u001b[0m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0;32m-> 2047\u001b[0;31m                                             value, tb, tb_offset=tb_offset)\n\u001b[0m\u001b[1;32m   2048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2049\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_showtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1435\u001b[0m         return FormattedTB.structured_traceback(\n\u001b[0;32m-> 1436\u001b[0;31m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0m\u001b[1;32m   1437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1334\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m             return VerboseTB.structured_traceback(\n\u001b[0;32m-> 1336\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m             )\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Minimal'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1209\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1210\u001b[0m             formatted_exceptions += self.format_exception_as_a_whole(etype, evalue, etb, lines_of_context,\n\u001b[0;32m-> 1211\u001b[0;31m                                                                      chained_exceptions_tb_offset)\n\u001b[0m\u001b[1;32m   1212\u001b[0m             \u001b[0mexception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_parts_of_chained_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1150\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "train_ANN_com = TrainCombined(\n",
    "                    bnn = False,\n",
    "                    model=h_ann_com,\n",
    "                    opt=opt_h_ann_com,\n",
    "                    training_loader=training_loader_original,\n",
    "                    validation_loader=validation_loader_original,\n",
    "                    OP = cn_constrained,\n",
    "                    dev = dev\n",
    "                )\n",
    "\n",
    "train_ANN_com.train(EPOCHS=35)\n",
    "model_ann_com = train_ANN_com.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_BNN_dec = TrainDecoupled(\n",
    "                    bnn = True,\n",
    "                    model=h_bnn_dec,\n",
    "                    opt=opt_h_bnn_dec,\n",
    "                    loss_data=mse_loss,\n",
    "                    K=0.0,\n",
    "                    training_loader=training_loader_original,\n",
    "                    validation_loader=validation_loader_original,\n",
    "                    dev = dev\n",
    "                )\n",
    "\n",
    "train_BNN_dec.train(EPOCHS=EPOCHS)\n",
    "model_bnn_dec = train_BNN_dec.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_BNN_com = TrainCombined(\n",
    "                    bnn = True,\n",
    "                    model=h_bnn_com,\n",
    "                    opt=opt_h_bnn_com,\n",
    "                    training_loader=training_loader_original,\n",
    "                    validation_loader=validation_loader_original,\n",
    "                    OP = cn_constrained_dist,\n",
    "                    dev=dev\n",
    "                )\n",
    "\n",
    "train_BNN_com.train(EPOCHS=8)\n",
    "model_bnn_com = train_BNN_com.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trfl = TrainFlowDecoupled(steps = 5000, input_size=4, output_size=8)\n",
    "pyx = trfl.train(X, Y, X_val, Y_val)\n",
    "model_flow_dec = pyx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training regression with FLOW\n",
    "trfl = TrainFlowCombined(\n",
    "    steps = 250, \n",
    "    input_size=4,\n",
    "    output_size=8,\n",
    "    lr=8e-3, \n",
    "    OP = cn_constrained_dist,\n",
    "    n_samples=N_SAMPLES*4)\n",
    "pyx = trfl.train(X, Y, X_val, Y_val)\n",
    "model_flow_com = pyx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Propagating predictions to Newsvendor Problem\n",
    "\n",
    "\n",
    "Y_pred_ANN_dec = model_ann_dec(X_val).unsqueeze(0)\n",
    "Y_pred_ANN_dec = inverse_transform(Y_pred_ANN_dec)\n",
    "\n",
    "Y_pred_ANN_com = model_ann_com(X_val).unsqueeze(0)\n",
    "Y_pred_ANN_com = inverse_transform(Y_pred_ANN_com)\n",
    "\n",
    "M = 4\n",
    "model_bnn_dec.update_n_samples(n_samples=M)\n",
    "Y_pred_BNN_dec = train_BNN_dec.model.forward_dist(X_val)\n",
    "Y_pred_BNN_dec = inverse_transform(Y_pred_BNN_dec)\n",
    "\n",
    "model_bnn_com.update_n_samples(n_samples=M)\n",
    "Y_pred_BNN_com = train_BNN_com.model.forward_dist(X_val)\n",
    "Y_pred_BNN_com = inverse_transform(Y_pred_BNN_com)\n",
    "M = Y_pred_BNN_com.shape[0]\n",
    "\n",
    "N = X_val.shape[0]\n",
    "Y_pred_flow_dec = torch.zeros((M, N, n_items))\n",
    "for i in range(0, N):\n",
    "    Y_pred_flow_dec[:,i,:] = model_flow_dec.condition(X_val[i]).sample(torch.Size([M,])).squeeze()\n",
    "Y_pred_flow_dec = inverse_transform(Y_pred_flow_dec)\n",
    "\n",
    "#Y_pred_flow_com = torch.zeros((M, N, n_items))\n",
    "#for i in range(0, N):\n",
    "#    Y_pred_flow_com[:,i,:] = model_com.condition(X_val[i]).sample(torch.Size([M,])).squeeze()\n",
    "#Y_pred_flow_com = inverse_transform(Y_pred_flow_com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_loss = nn.MSELoss()\n",
    "print(mse_loss(Y_pred_ANN_dec.mean(axis=0), Y_val_original))\n",
    "print(mse_loss(Y_pred_ANN_com.mean(axis=0), Y_val_original))\n",
    "\n",
    "print(mse_loss(Y_pred_BNN_dec.mean(axis=0), Y_val_original))\n",
    "print(mse_loss(Y_pred_BNN_com.mean(axis=0), Y_val_original))\n",
    "\n",
    "print(mse_loss(Y_pred_flow_dec.mean(axis=0), Y_val_original))\n",
    "#print(mse_loss(Y_pred_flow_com.mean(axis=0), Y_val_original))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Construct the solver\n",
    "newsvendor_solve_kkt = SolveNewsvendorWithKKT(params_t, 1)\n",
    "newsvendor_solve_kkt_M = SolveNewsvendorWithKKT(params_t, M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_final_block(Y_pred, cost):\n",
    "\n",
    "    n_batches = int(np.ceil(Y_pred.shape[1]/BATCH_SIZE_LOADER))\n",
    "\n",
    "    f_total = 0\n",
    "    f_total_best = 0\n",
    "\n",
    "    for b in range(0, n_batches):\n",
    "        i_low = b*BATCH_SIZE_LOADER\n",
    "        i_up = (b+1)*BATCH_SIZE_LOADER\n",
    "        if b == n_batches-1:\n",
    "            i_up = n_batches*Y_pred.shape[1]\n",
    "        f_total += cost(Y_pred[:,i_low:i_up,:], Y_val_original[i_low:i_up,:])/n_batches\n",
    "        print(b, f_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optimize_final_block(Y_pred_ANN_dec, newsvendor_solve_kkt.end_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optimize_final_block(Y_pred_ANN_com, newsvendor_solve_kkt.end_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimize_final_block(Y_pred_BNN_dec, newsvendor_solve_kkt_M.end_loss_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimize_final_block(Y_pred_BNN_com, newsvendor_solve_kkt_M.end_loss_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimize_final_block(Y_pred_flow_dec, newsvendor_solve_kkt_M.end_loss_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def argmin_solver(Y_pred):\n",
    "            z_star = newsvendor_solve_kkt_M.forward(Y_pred)\n",
    "            return z_star\n",
    "\n",
    "optimize_final_block(Y_pred_BNN_dec, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimize_final_block(Y_pred_BNN_com, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimize_final_block(Y_pred_flow_dec, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimize_final_block(Y_pred_flow_com, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def argmin_solver(y_pred):\n",
    "    z_star = newsvendor_solve_kkt.forward(y_pred)\n",
    "    return z_star\n",
    "\n",
    "n_batches = int(np.ceil(Y_pred_ANN_dec.shape[1]/BATCH_SIZE_LOADER))\n",
    "\n",
    "f_total = 0\n",
    "f_total_best = 0\n",
    "\n",
    "for b in range(0, n_batches):\n",
    "    i_low = b*BATCH_SIZE_LOADER\n",
    "    i_up = (b+1)*BATCH_SIZE_LOADER\n",
    "    if b == n_batches-1:\n",
    "        i_up = n_batches*Y_pred_ANN_dec.shape[1]\n",
    "    f_total += cost_fn(Y_pred_ANN_dec[:,i_low:i_up,:], Y_val_original[i_low:i_up,:])/n_batches\n",
    "    print(b, f_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def argmin_solver(y_pred):\n",
    "    z_star = newsvendor_solve_kkt_M.forward(y_pred)\n",
    "    return z_star\n",
    "\n",
    "n_batches = int(np.ceil(Y_pred_BNN.shape[1]/BATCH_SIZE_LOADER))\n",
    "\n",
    "f_total = 0\n",
    "f_total_best = 0\n",
    "\n",
    "for b in range(0, n_batches):\n",
    "    i_low = b*BATCH_SIZE_LOADER\n",
    "    i_up = (b+1)*BATCH_SIZE_LOADER\n",
    "    if b == n_batches-1:\n",
    "        i_up = n_batches*Y_pred_BNN.shape[1]\n",
    "    f_total += cost_fn(Y_pred_BNN[:,i_low:i_up,:], Y_val_original[i_low:i_up,:])/n_batches\n",
    "    print(b, f_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def argmin_solver(y_pred):\n",
    "    z_star = newsvendor_solve_kkt_M.forward(y_pred)\n",
    "    return z_star\n",
    "\n",
    "n_batches = int(np.ceil(Y_pred_flow.shape[1]/BATCH_SIZE_LOADER))\n",
    "\n",
    "f_total = 0\n",
    "f_total_best = 0\n",
    "\n",
    "for b in range(0, n_batches):\n",
    "    i_low = b*BATCH_SIZE_LOADER\n",
    "    i_up = (b+1)*BATCH_SIZE_LOADER\n",
    "    if b == n_batches-1:\n",
    "        i_up = n_batches*Y_pred_flow.shape[1]\n",
    "    f_total += cost_fn(Y_pred_flow[:,i_low:i_up,:], Y_val_original[i_low:i_up,:])/n_batches\n",
    "    print(b, f_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_val_original.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def argmin_solver(y_pred):\n",
    "    z_star = newsvendor_solve_kkt.forward(y_pred)\n",
    "    return z_star\n",
    "\n",
    "n_batches = int(np.ceil(Y_val_original.shape[0]/BATCH_SIZE_LOADER))\n",
    "\n",
    "f_total = 0\n",
    "f_total_best = 0\n",
    "\n",
    "for b in range(0, n_batches):\n",
    "    i_low = b*BATCH_SIZE_LOADER\n",
    "    i_up = (b+1)*BATCH_SIZE_LOADER\n",
    "    if b == n_batches-1:\n",
    "        i_up = n_batches*Y_val_original.shape[0]\n",
    "    f_total += cost_fn(Y_val_original[i_low:i_up,:].unsqueeze(0), Y_val_original[i_low:i_up,:])/n_batches\n",
    "    print(f_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(argmin_solver(reshape_outcomes(Y_val_original[0:50,:].unsqueeze(0)))*params_t['pr']).sum(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.83 1.64 2.43 28104 27870 27787 13598\n",
    "1.87 1.89 2.46 42607 42070 41574 28124\n",
    "1.80 1.85 2.25 34329 33855 33395 15849\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
