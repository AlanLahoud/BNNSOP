{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch.multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_cuda = False\n",
    "dev = torch.device('cpu')  \n",
    "if torch.cuda.is_available():\n",
    "    is_cuda = True\n",
    "    dev = torch.device('cuda')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = np.random.normal(3, 2, N)\n",
    "x2 = np.random.normal(0, 5, N)\n",
    "\n",
    "X = np.vstack((x1, x2)).T\n",
    "\n",
    "# Noise\n",
    "n1 = np.random.normal(0, 2, N)\n",
    "n2 = np.random.normal(0, 6, N)\n",
    "n3 = np.random.normal(0, 10, N)\n",
    "\n",
    "y1 = x1**2 + 5*x1*x2 + 3*np.abs(x2) + n1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.tensor(X[:800], requires_grad= True, device=dev)\n",
    "y1_train = torch.tensor(y1[:800], requires_grad= True, device=dev)\n",
    "\n",
    "X_test = torch.tensor(X[800:], requires_grad= True, device=dev)\n",
    "y1_test = torch.tensor(y1[800:], requires_grad= True, device=dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VariationalLayer(nn.Module):\n",
    "    def __init__(self, \n",
    "                 input_size, output_size,\n",
    "                 prior_mu, prior_rho,\n",
    "                 theta_mu_init, theta_rho_init\n",
    "                ):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Bias weight\n",
    "        input_size = input_size + 1\n",
    "        \n",
    "        # Defining Prior distribution (Gaussian)\n",
    "        self.prior_mu = torch.tensor(prior_mu)\n",
    "        self.prior_rho = torch.tensor(prior_rho)\n",
    "        \n",
    "        # Defining Variational class (Gaussian class)\n",
    "        self.theta_mu = nn.Parameter(\n",
    "            torch.Tensor(output_size, input_size).uniform_(-0.2, 0.2))\n",
    "        self.theta_rho = nn.Parameter(\n",
    "            torch.Tensor(output_size, input_size).uniform_(-2,-1))\n",
    "        \n",
    "        # Defining some constants\n",
    "        self.logsqrttwopi = torch.log(\n",
    "            torch.sqrt(2*torch.tensor(torch.pi)))\n",
    "        self.K = torch.tensor(1)\n",
    "    \n",
    "    def rho_to_sigma(self, theta_rho):\n",
    "        return torch.log(1 + torch.exp(theta_rho))\n",
    "\n",
    "    def sample_weight(self, theta_mu, theta_rho):\n",
    "        w = (theta_mu \n",
    "        + self.rho_to_sigma(theta_rho)*torch.randn(theta_mu.shape))\n",
    "        return w\n",
    "\n",
    "    def log_prob_gaussian(self, x, mu, rho):\n",
    "            return (\n",
    "                - self.logsqrttwopi\n",
    "                - self.rho_to_sigma(rho)\n",
    "                - ((x - mu)**2)/(2*self.rho_to_sigma(rho)**2)\n",
    "            ).sum()\n",
    "    \n",
    "    def prior(self, w):\n",
    "        return self.log_prob_gaussian(\n",
    "            w, self.prior_mu, self.prior_rho)\n",
    "        \n",
    "    def variational(self, w, theta_mu, theta_rho):\n",
    "        return self.log_prob_gaussian(\n",
    "            w, theta_mu, theta_rho) \n",
    "    \n",
    "    def forward(self, x_layer):\n",
    "        theta_mu = self.theta_mu\n",
    "        theta_rho = self.theta_rho\n",
    "        w = self.sample_weight(theta_mu, theta_rho)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BayesianLinear(nn.Module):\n",
    "    def __init__(self, layer_size, next_layer_size):\n",
    "        super().__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        # Weight parameters\n",
    "        self.variat_mu = nn.Parameter(torch.Tensor(next_layer_size, layer_size+1).uniform_(-0.2, 0.2))\n",
    "        self.variat_rho = nn.Parameter(torch.Tensor(next_layer_size, layer_size).uniform_(-2,-1))\n",
    "        self.weight = VariationalInference(self.weight_mu, self.weight_rho)\n",
    "        # Bias parameters\n",
    "        self.bias_mu = nn.Parameter(torch.Tensor(out_features).uniform_(-0.2, 0.2))\n",
    "        self.bias_rho = nn.Parameter(torch.Tensor(out_features).uniform_(-5,-4))\n",
    "        self.bias = Gaussian(self.bias_mu, self.bias_rho)\n",
    "        # Prior distributions\n",
    "        self.weight_prior = ScaleMixtureGaussian(PI, SIGMA_1, SIGMA_2)\n",
    "        self.bias_prior = ScaleMixtureGaussian(PI, SIGMA_1, SIGMA_2)\n",
    "        self.log_prior = 0\n",
    "        self.log_variational_posterior = 0\n",
    "\n",
    "    def forward(self, x_layer, sample=False, calculate_log_probs=False):\n",
    "        x_next_layer = \n",
    "\n",
    "        return F.linear(input, weight, bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANN(nn.Module):\n",
    "    # Initialize the layers\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.act1 = nn.ReLU()\n",
    "        self.linear1 = nn.Linear(input_size, 6).double()\n",
    "        self.bn = nn.BatchNorm1d(6).double()\n",
    "        self.linear2 = nn.Linear(6, output_size).double()\n",
    "    \n",
    "    # Perform the computation\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.act1(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.act1(x)\n",
    "        return x\n",
    "    \n",
    "    def forward_parallel(self, x_samples):\n",
    "        with mp.Pool(processes = 2) as p:\n",
    "            results = p.map(self.forward, x_samples)\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(0, 8)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.multiprocessing import Pool\n",
    "\n",
    "X = np.array([[1, 3, 2, 3], [2, 3, 5, 6], [1, 2, 3, 4]])\n",
    "X = torch.DoubleTensor(X).cuda()\n",
    "\n",
    "def X_power_func(j):\n",
    "    X_power = X**j\n",
    "    return X_power\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  with Pool(processes = 2) as p:   # Paralleizing over 2 GPUs\n",
    "    results = p.map(X_power_func, range(8))\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 2\n",
    "output_size = 1\n",
    "\n",
    "weight_mu = nn.Parameter(torch.Tensor(output_size, input_size).uniform_(-0.2, 0.2))\n",
    "weight_rho = nn.Parameter(torch.Tensor(output_size, input_size).uniform_(-2,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "vi_obj = VariationalInference(0, 0.54, weight_mu, weight_rho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = ANN(input_size, output_size).to(dev)\n",
    "opt_h = torch.optim.Adam(h.parameters(), lr=0.001)\n",
    "\n",
    "mse_loss = nn.MSELoss(reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'elbo_loss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [33]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43melbo_loss\u001b[49m(xh, yh, h, w)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'elbo_loss' is not defined"
     ]
    }
   ],
   "source": [
    "elbo_loss(xh, yh, h, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-3.9606, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = vi_obj.sample_weight(weight_mu, weight_rho)\n",
    "Q = vi_obj.variational(w, weight_mu, weight_rho)\n",
    "P = vi_obj.variational(w)\n",
    "\n",
    "index = np.random.randint(0, 800, 5)\n",
    "x_h = X_train[index]\n",
    "y_h = y1_train[index]\n",
    "l = mse_loss(h(x_h), y_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0624],\n",
       "        [0.0000],\n",
       "        [0.0701],\n",
       "        [0.2169],\n",
       "        [0.1127]], dtype=torch.float64, grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h(x_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([200, 2])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Cowardly refusing to serialize non-leaf tensor which requires_grad, since autograd does not support crossing process boundaries.  If you just want to transfer the data, call detach() on the tensor before serializing (e.g., putting it on the queue).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [130]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mh\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_parallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_h\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [128]\u001b[0m, in \u001b[0;36mANN.forward_parallel\u001b[0;34m(self, x_samples)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward_parallel\u001b[39m(\u001b[38;5;28mself\u001b[39m, x_samples):\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m mp\u001b[38;5;241m.\u001b[39mPool(processes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m p:\n\u001b[0;32m---> 22\u001b[0m         results \u001b[38;5;241m=\u001b[39m \u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_samples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "File \u001b[0;32m/usr/lib/python3.8/multiprocessing/pool.py:364\u001b[0m, in \u001b[0;36mPool.map\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, iterable, chunksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    360\u001b[0m     \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;124;03m    Apply `func` to each element in `iterable`, collecting the results\u001b[39;00m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;124;03m    in a list that is returned.\u001b[39;00m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 364\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapstar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.8/multiprocessing/pool.py:771\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    769\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n\u001b[1;32m    770\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 771\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "File \u001b[0;32m/usr/lib/python3.8/multiprocessing/pool.py:537\u001b[0m, in \u001b[0;36mPool._handle_tasks\u001b[0;34m(taskqueue, put, outqueue, pool, cache)\u001b[0m\n\u001b[1;32m    535\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    536\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 537\u001b[0m     \u001b[43mput\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    539\u001b[0m     job, idx \u001b[38;5;241m=\u001b[39m task[:\u001b[38;5;241m2\u001b[39m]\n",
      "File \u001b[0;32m/usr/lib/python3.8/multiprocessing/connection.py:206\u001b[0m, in \u001b[0;36m_ConnectionBase.send\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_writable()\n\u001b[0;32m--> 206\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_bytes(\u001b[43m_ForkingPickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/usr/lib/python3.8/multiprocessing/reduction.py:51\u001b[0m, in \u001b[0;36mForkingPickler.dumps\u001b[0;34m(cls, obj, protocol)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdumps\u001b[39m(\u001b[38;5;28mcls\u001b[39m, obj, protocol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     50\u001b[0m     buf \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mBytesIO()\n\u001b[0;32m---> 51\u001b[0m     \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbuf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m buf\u001b[38;5;241m.\u001b[39mgetbuffer()\n",
      "File \u001b[0;32m~/Desktop/envs/pao_env/lib/python3.8/site-packages/torch/multiprocessing/reductions.py:143\u001b[0m, in \u001b[0;36mreduce_tensor\u001b[0;34m(tensor)\u001b[0m\n\u001b[1;32m    140\u001b[0m storage \u001b[38;5;241m=\u001b[39m tensor\u001b[38;5;241m.\u001b[39mstorage()\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tensor\u001b[38;5;241m.\u001b[39mrequires_grad \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tensor\u001b[38;5;241m.\u001b[39mis_leaf:\n\u001b[0;32m--> 143\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCowardly refusing to serialize non-leaf tensor which requires_grad, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    144\u001b[0m                        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msince autograd does not support crossing process boundaries.  \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    145\u001b[0m                        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf you just want to transfer the data, call detach() on the tensor \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    146\u001b[0m                        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbefore serializing (e.g., putting it on the queue).\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    148\u001b[0m check_serializing_named_tensor(tensor)\n\u001b[1;32m    149\u001b[0m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mhooks\u001b[38;5;241m.\u001b[39mwarn_if_has_hooks(tensor)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Cowardly refusing to serialize non-leaf tensor which requires_grad, since autograd does not support crossing process boundaries.  If you just want to transfer the data, call detach() on the tensor before serializing (e.g., putting it on the queue)."
     ]
    }
   ],
   "source": [
    "h.forward_parallel(x_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.41972735,  1.2029036 ],\n",
       "       [ 3.64036384, -1.80001503],\n",
       "       [ 1.66258872, -9.45797395],\n",
       "       ...,\n",
       "       [ 3.35859904,  2.77637386],\n",
       "       [ 2.11101038,  5.22272453],\n",
       "       [ 2.69671436,  2.78818971]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = vi_obj.prior(vi_obj.sample_weight(weight_mu, weight_rho))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = np.random.randint(0, 800, 200)\n",
    "x_h = X_train[index]\n",
    "y_h = y1_train[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.2213e+00, -6.2528e+00],\n",
       "        [ 2.7539e+00,  2.2754e+00],\n",
       "        [ 4.8483e+00, -3.6463e+00],\n",
       "        [ 4.6008e+00, -2.2948e+00],\n",
       "        [ 6.7030e+00, -2.3596e+00],\n",
       "        [ 1.8571e+00,  6.8027e-01],\n",
       "        [ 2.9115e+00, -5.4428e+00],\n",
       "        [ 2.3574e+00, -4.6242e+00],\n",
       "        [ 4.1867e+00, -5.0198e+00],\n",
       "        [ 5.5665e+00,  1.7493e+00],\n",
       "        [ 4.1867e+00, -5.0198e+00],\n",
       "        [ 1.6467e+00, -1.4431e+00],\n",
       "        [ 1.7152e+00, -2.6472e+00],\n",
       "        [ 4.8483e+00, -3.6463e+00],\n",
       "        [ 3.3220e+00,  3.2644e+00],\n",
       "        [ 1.7996e+00, -6.0863e+00],\n",
       "        [ 9.8054e-01,  3.7539e+00],\n",
       "        [ 5.2619e+00, -2.2712e+00],\n",
       "        [ 5.8081e+00,  4.0490e+00],\n",
       "        [ 5.0169e+00,  3.7023e+00],\n",
       "        [ 7.5814e-01,  3.0518e-01],\n",
       "        [ 4.2604e+00,  5.6789e+00],\n",
       "        [ 7.5471e+00, -1.5020e+00],\n",
       "        [ 6.1520e+00,  4.9272e+00],\n",
       "        [ 4.3850e+00,  2.8569e+00],\n",
       "        [ 4.5348e+00,  3.5263e+00],\n",
       "        [ 3.4467e+00, -4.1564e+00],\n",
       "        [-1.3712e+00,  3.6505e+00],\n",
       "        [ 3.8401e+00,  3.3312e+00],\n",
       "        [ 5.3668e+00, -4.8615e+00],\n",
       "        [ 2.0427e+00,  9.1059e-01],\n",
       "        [ 1.1735e+00,  7.7315e+00],\n",
       "        [-2.2564e+00,  1.1066e+00],\n",
       "        [ 3.7575e+00,  3.5623e+00],\n",
       "        [ 3.1006e+00, -2.8287e+00],\n",
       "        [ 2.5677e+00,  2.1725e+00],\n",
       "        [ 3.6404e+00, -1.8000e+00],\n",
       "        [ 4.0081e+00, -5.1534e+00],\n",
       "        [ 6.4448e+00,  2.7751e+00],\n",
       "        [ 2.0561e+00,  4.1414e-02],\n",
       "        [ 2.1654e+00,  1.3357e+00],\n",
       "        [ 6.1574e+00,  1.1348e+01],\n",
       "        [ 5.1213e+00, -1.0509e+01],\n",
       "        [ 7.2335e-01, -6.1377e+00],\n",
       "        [ 4.6861e+00,  5.6095e+00],\n",
       "        [ 3.4809e+00,  7.0722e-03],\n",
       "        [ 2.3574e+00, -4.6242e+00],\n",
       "        [ 9.9098e-01,  2.2986e+00],\n",
       "        [-1.0013e+00,  4.1154e+00],\n",
       "        [ 5.0149e+00, -5.0131e+00],\n",
       "        [ 5.7128e+00,  2.7622e+00],\n",
       "        [ 4.2478e+00, -1.1957e+00],\n",
       "        [ 4.1419e+00, -8.5059e+00],\n",
       "        [-3.1216e+00,  3.0758e+00],\n",
       "        [ 4.5348e+00,  3.5263e+00],\n",
       "        [ 7.6920e-01,  4.8152e+00],\n",
       "        [-1.5647e+00, -2.9344e+00],\n",
       "        [ 3.5575e+00,  6.9786e-01],\n",
       "        [ 1.1837e+00, -3.3843e+00],\n",
       "        [ 4.4847e+00,  2.9122e+00],\n",
       "        [ 3.7996e+00,  4.0384e-02],\n",
       "        [ 2.7150e-01,  1.5182e+00],\n",
       "        [ 1.6258e+00,  9.2874e+00],\n",
       "        [ 3.2481e+00,  7.2629e-01],\n",
       "        [ 2.3549e+00,  2.2191e+00],\n",
       "        [ 3.6404e+00, -1.8000e+00],\n",
       "        [ 2.0960e+00,  8.9925e+00],\n",
       "        [ 4.4070e+00, -5.7698e+00],\n",
       "        [ 4.0478e+00,  4.1103e-01],\n",
       "        [ 5.2619e+00, -2.2712e+00],\n",
       "        [-4.2075e-01,  2.6132e+00],\n",
       "        [ 3.7796e+00, -1.2589e+00],\n",
       "        [ 5.4074e+00,  9.6498e+00],\n",
       "        [ 3.0450e+00,  9.7262e+00],\n",
       "        [ 4.1867e+00, -6.3441e+00],\n",
       "        [ 2.3549e+00,  2.2191e+00],\n",
       "        [-2.9575e-01, -5.0211e+00],\n",
       "        [ 2.4067e+00,  5.8433e+00],\n",
       "        [ 2.6122e+00,  3.1011e+00],\n",
       "        [ 4.0457e+00, -3.0625e+00],\n",
       "        [ 1.4471e+00, -4.8653e+00],\n",
       "        [ 6.1503e+00, -5.2530e+00],\n",
       "        [ 5.0540e+00,  5.2491e+00],\n",
       "        [ 4.4573e+00, -5.1979e+00],\n",
       "        [ 4.1073e+00,  2.6293e+00],\n",
       "        [ 4.6861e+00,  5.6095e+00],\n",
       "        [ 1.2264e+00, -2.2595e+00],\n",
       "        [ 1.0373e+00, -4.0995e+00],\n",
       "        [ 6.0379e+00,  3.4194e-01],\n",
       "        [ 3.0735e+00, -5.8397e+00],\n",
       "        [ 4.6008e+00, -2.2948e+00],\n",
       "        [ 4.3111e+00,  7.0796e+00],\n",
       "        [ 3.1874e+00,  8.8398e+00],\n",
       "        [ 5.0781e+00,  1.1830e+01],\n",
       "        [ 2.3325e+00, -2.6037e+00],\n",
       "        [ 2.7069e+00, -4.2269e+00],\n",
       "        [ 6.4448e+00,  2.7751e+00],\n",
       "        [ 1.0955e+00, -5.3721e+00],\n",
       "        [ 3.1681e+00, -9.9816e-01],\n",
       "        [ 2.4690e+00,  2.5959e+00],\n",
       "        [-8.4587e-01,  7.3888e-02],\n",
       "        [ 3.2975e+00, -4.8681e+00],\n",
       "        [ 1.2946e+00,  7.7900e+00],\n",
       "        [ 4.4753e+00,  1.2577e+00],\n",
       "        [ 1.7996e+00, -6.0863e+00],\n",
       "        [ 2.0904e+00,  2.4417e-01],\n",
       "        [ 2.5805e+00, -5.6564e+00],\n",
       "        [ 4.6441e+00, -7.0014e-01],\n",
       "        [ 1.8060e+00, -5.1491e+00],\n",
       "        [ 3.2947e+00,  2.7953e+00],\n",
       "        [ 4.5230e+00,  3.3684e+00],\n",
       "        [ 1.0877e+00,  9.4003e+00],\n",
       "        [ 1.6258e+00,  9.2874e+00],\n",
       "        [ 1.1799e+00,  8.1679e+00],\n",
       "        [ 2.9100e+00, -5.3686e+00],\n",
       "        [ 4.3130e+00,  1.8640e+00],\n",
       "        [ 4.2007e-01,  8.8226e+00],\n",
       "        [ 5.5185e+00,  1.5456e+00],\n",
       "        [-1.3684e+00, -3.0266e+00],\n",
       "        [ 1.1799e+00,  8.1679e+00],\n",
       "        [ 2.0727e+00,  6.9472e+00],\n",
       "        [ 3.0737e+00,  3.3305e-01],\n",
       "        [ 5.4783e+00,  2.3917e+00],\n",
       "        [ 1.0122e+00,  9.3832e-01],\n",
       "        [ 4.4258e+00, -1.8501e+00],\n",
       "        [ 2.4579e+00,  4.1520e-01],\n",
       "        [ 4.6880e+00,  2.1946e+00],\n",
       "        [ 1.1735e+00,  7.7315e+00],\n",
       "        [ 2.6284e+00,  6.4786e+00],\n",
       "        [ 3.9744e+00,  6.2589e+00],\n",
       "        [ 4.9426e+00, -3.6281e+00],\n",
       "        [ 1.3175e+00, -4.5762e-01],\n",
       "        [ 4.5269e+00, -2.4364e+00],\n",
       "        [ 4.4573e+00, -5.1979e+00],\n",
       "        [ 2.1711e-01,  6.5833e+00],\n",
       "        [ 1.3187e+00, -1.2044e-01],\n",
       "        [-1.5647e+00, -2.9344e+00],\n",
       "        [ 4.4989e+00, -3.2355e+00],\n",
       "        [ 1.0122e+00,  9.3832e-01],\n",
       "        [ 3.1567e+00, -1.4761e-01],\n",
       "        [ 1.1714e+00,  1.0239e+01],\n",
       "        [ 2.7156e+00,  6.9025e+00],\n",
       "        [ 4.6857e+00, -6.5394e+00],\n",
       "        [ 2.1348e+00,  8.4103e-02],\n",
       "        [ 1.7051e+00,  6.8187e+00],\n",
       "        [ 3.4467e+00, -4.1564e+00],\n",
       "        [ 5.3558e+00, -7.2359e-01],\n",
       "        [ 5.1163e+00,  2.9896e+00],\n",
       "        [ 3.0702e+00, -2.0315e+00],\n",
       "        [ 1.4197e+00,  1.2029e+00],\n",
       "        [ 3.9201e+00,  8.9298e+00],\n",
       "        [ 1.7936e+00,  1.7860e+00],\n",
       "        [ 3.3532e+00,  5.8603e+00],\n",
       "        [ 4.2265e+00, -4.7608e+00],\n",
       "        [ 7.2811e-01, -3.6428e-01],\n",
       "        [ 1.5127e+00, -3.5730e+00],\n",
       "        [ 5.8625e+00,  4.5118e+00],\n",
       "        [ 4.9048e-01,  1.3626e+01],\n",
       "        [ 3.2787e+00,  1.7774e+00],\n",
       "        [ 2.3934e+00, -3.2097e+00],\n",
       "        [ 5.0204e+00,  2.5834e+00],\n",
       "        [-5.2047e-01,  9.0772e+00],\n",
       "        [ 2.1881e+00,  8.0024e+00],\n",
       "        [ 2.3147e+00,  8.4183e-02],\n",
       "        [ 4.0478e+00,  4.1103e-01],\n",
       "        [ 2.5738e+00, -2.9967e+00],\n",
       "        [ 3.4649e+00, -1.1076e+01],\n",
       "        [ 4.0303e+00,  2.0800e+00],\n",
       "        [ 3.4467e+00, -4.1564e+00],\n",
       "        [ 6.4624e+00,  1.0276e-01],\n",
       "        [ 3.8186e+00, -1.0165e+00],\n",
       "        [ 3.7575e+00,  3.5623e+00],\n",
       "        [ 3.7712e+00, -3.3082e+00],\n",
       "        [ 2.4579e+00,  4.1520e-01],\n",
       "        [-1.0394e+00, -1.3418e+00],\n",
       "        [ 3.1529e+00, -2.9057e+00],\n",
       "        [ 1.7739e+00,  1.3703e+00],\n",
       "        [ 3.2008e+00, -7.6072e+00],\n",
       "        [ 4.5230e+00,  3.3684e+00],\n",
       "        [ 1.5127e+00, -3.5730e+00],\n",
       "        [ 5.1177e+00, -3.8126e+00],\n",
       "        [ 2.9648e-01, -1.1864e+00],\n",
       "        [ 2.0427e+00,  9.1059e-01],\n",
       "        [ 5.2619e-01,  2.5396e+00],\n",
       "        [ 2.8876e+00, -4.4858e+00],\n",
       "        [ 4.4635e+00, -5.6835e+00],\n",
       "        [ 2.5821e+00, -1.5985e+00],\n",
       "        [ 1.5695e+00, -5.5184e+00],\n",
       "        [ 8.7105e-01,  2.5179e+00],\n",
       "        [ 3.2043e+00, -9.6052e-01],\n",
       "        [ 5.8081e+00,  4.0490e+00],\n",
       "        [ 2.5944e+00,  7.8854e+00],\n",
       "        [ 3.8856e+00,  4.2251e+00],\n",
       "        [ 4.4635e+00, -5.6835e+00],\n",
       "        [ 6.1503e+00, -5.2530e+00],\n",
       "        [ 1.3400e+00, -2.6819e+00],\n",
       "        [ 5.9189e+00,  4.6587e+00],\n",
       "        [ 6.3695e+00, -4.6322e+00],\n",
       "        [ 4.4385e-01,  8.5420e+00],\n",
       "        [ 1.2264e+00, -2.2595e+00]], dtype=torch.float64,\n",
       "       grad_fn=<IndexBackward0>)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "463"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randint(0,N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(8096.7533, dtype=torch.float64, grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_loss(h(x_h), y_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = sample_weight(weight_mu, weight_rho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0181, -0.4754]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-3.9496, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prior(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-4.1615, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variational_posterior(w, weight_mu, weight_rho)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pao_env",
   "language": "python",
   "name": "pao_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
